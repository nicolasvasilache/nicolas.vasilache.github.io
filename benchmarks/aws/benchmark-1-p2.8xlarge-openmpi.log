+ which mpicc
/data/torch_mpi/openmpi-2.0.1/bin/mpicc
+ which mpirun
/data/torch_mpi/openmpi-2.0.1/bin/mpirun
+ nvidia-smi -q -i 0 -d CLOCK

==============NVSMI LOG==============

Timestamp                           : Thu Nov  3 18:37:28 2016
Driver Version                      : 352.99

Attached GPUs                       : 8
GPU 0000:00:17.0
    Clocks
        Graphics                    : 324 MHz
        SM                          : 324 MHz
        Memory                      : 324 MHz
    Applications Clocks
        Graphics                    : 875 MHz
        Memory                      : 2505 MHz
    Default Applications Clocks
        Graphics                    : 562 MHz
        Memory                      : 2505 MHz
    Max Clocks
        Graphics                    : 875 MHz
        SM                          : 875 MHz
        Memory                      : 2505 MHz
    SM Clock Samples
        Duration                    : 15033.17 sec
        Number of Samples           : 100
        Max                         : 875 MHz
        Min                         : 324 MHz
        Avg                         : 858 MHz
    Memory Clock Samples
        Duration                    : 15033.17 sec
        Number of Samples           : 100
        Max                         : 2505 MHz
        Min                         : 324 MHz
        Avg                         : 2495 MHz
    Clock Policy
        Auto Boost                  : On
        Auto Boost Default          : On

+ nvidia-smi topo --matrix
	[4mGPU0	GPU1	GPU2	GPU3	GPU4	GPU5	GPU6	GPU7	CPU Affinity[0m
GPU0	 X 	PHB	PHB	PHB	PHB	PHB	PHB	PHB	0-31
GPU1	PHB	 X 	PHB	PHB	PHB	PHB	PHB	PHB	0-31
GPU2	PHB	PHB	 X 	PHB	PHB	PHB	PHB	PHB	0-31
GPU3	PHB	PHB	PHB	 X 	PHB	PHB	PHB	PHB	0-31
GPU4	PHB	PHB	PHB	PHB	 X 	PHB	PHB	PHB	0-31
GPU5	PHB	PHB	PHB	PHB	PHB	 X 	PHB	PHB	0-31
GPU6	PHB	PHB	PHB	PHB	PHB	PHB	 X 	PHB	0-31
GPU7	PHB	PHB	PHB	PHB	PHB	PHB	PHB	 X 	0-31

Legend:

  X   = Self
  SOC = Path traverses a socket-level link (e.g. QPI)
  PHB = Path traverses a PCIe host bridge
  PXB = Path traverses multiple PCIe internal switches
  PIX = Path traverses a PCIe internal switch
++ echo '2 4 8'
++ tr ' ' '\n'
+ for nproc in '$(echo "2 4 8" | tr " " "\n")'
+ mpirun --bind-to none -n 2 luajit ./test/collectives.lua -all
[warning] MPI_Init_Thread only provides [warning] MPI_Init_Thread only provides 2 (asked for 3)
2 (asked for 3)
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (256 contiguous values) -> 4 us (0.249707 GB/s assuming good implementation, i.e. 0.001024 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (512 contiguous values) -> 20 us (0.098396 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (1024 contiguous values) -> 4 us (0.822003 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (2048 contiguous values) -> 6 us (1.258598 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (4096 contiguous values) -> 24 us (0.677039 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (8192 contiguous values) -> 12 us (2.540461 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (16384 contiguous values) -> 22 us (2.887373 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (32768 contiguous values) -> 46 us (2.836717 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (65536 contiguous values) -> 96 us (2.716185 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (131072 contiguous values) -> 182 us (2.879056 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (262144 contiguous values) -> 377 us (2.781285 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (524288 contiguous values) -> 797 us (2.629310 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (1048576 contiguous values) -> 1655 us (2.533729 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (2097152 contiguous values) -> 3436 us (2.441105 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (4194304 contiguous values) -> 7460 us (2.248864 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (8388608 contiguous values) -> 34720 us (0.966413 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (16777216 contiguous values) -> 70466 us (0.952354 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (256 contiguous values) -> 11 us (0.184333 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (512 contiguous values) -> 6 us (0.611383 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (1024 contiguous values) -> 5 us (1.487435 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (2048 contiguous values) -> 10 us (1.503708 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (4096 contiguous values) -> 10 us (3.033972 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (8192 contiguous values) -> 15 us (4.255076 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (16384 contiguous values) -> 25 us (5.201096 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (32768 contiguous values) -> 47 us (5.564330 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (65536 contiguous values) -> 93 us (5.584112 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (131072 contiguous values) -> 185 us (5.665395 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (262144 contiguous values) -> 368 us (5.688110 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (524288 contiguous values) -> 729 us (5.749456 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (1048576 contiguous values) -> 1444 us (5.808015 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (2097152 contiguous values) -> 2890 us (5.803656 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (4194304 contiguous values) -> 6174 us (5.434090 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (8388608 contiguous values) -> 14674 us (4.573193 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (16777216 contiguous values) -> 29932 us (4.483971 GB/s assuming good implementation, i.e. 134.217728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (256 contiguous values) -> 9 us (0.109009 GB/s assuming good implementation, i.e. 0.001024 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (512 contiguous values) -> 4 us (0.445074 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (1024 contiguous values) -> 2 us (1.455921 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (2048 contiguous values) -> 5 us (1.576135 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (4096 contiguous values) -> 7 us (2.101513 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (8192 contiguous values) -> 12 us (2.521816 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (16384 contiguous values) -> 23 us (2.765371 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (32768 contiguous values) -> 43 us (3.040685 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (65536 contiguous values) -> 76 us (3.408282 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (131072 contiguous values) -> 89 us (5.871891 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (262144 contiguous values) -> 173 us (6.057915 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (524288 contiguous values) -> 347 us (6.036712 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (1048576 contiguous values) -> 689 us (6.085788 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (2097152 contiguous values) -> 1374 us (6.102571 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (4194304 contiguous values) -> 2904 us (5.776263 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (8388608 contiguous values) -> 7529 us (4.456524 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (16777216 contiguous values) -> 15776 us (4.253616 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (256 contiguous values) -> 3 us (0.320520 GB/s assuming good implementation, i.e. 0.001024 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11684478976 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (512 contiguous values) -> 3 us (0.600695 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685543936 / 11684478976 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (1024 contiguous values) -> 4 us (0.854720 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685543936 / 11684478976 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (2048 contiguous values) -> 6 us (1.321528 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11684478976 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (4096 contiguous values) -> 8 us (1.997659 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11684478976 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (8192 contiguous values) -> 12 us (2.578592 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685535744 / 11684478976 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (16384 contiguous values) -> 22 us (2.939871 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685543936 / 11684478976 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (32768 contiguous values) -> 46 us (2.844055 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685535744 / 11684478976 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (65536 contiguous values) -> 91 us (2.877549 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685543936 / 11684478976 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (131072 contiguous values) -> 180 us (2.901469 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11684478976 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (262144 contiguous values) -> 382 us (2.740045 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685535744 / 11684478976 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (524288 contiguous values) -> 812 us (2.582680 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11682381824 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (1048576 contiguous values) -> 1677 us (2.500773 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11678187520 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (2097152 contiguous values) -> 3466 us (2.420049 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11669798912 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (4194304 contiguous values) -> 7693 us (2.180699 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11669807104 / 11653021696 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (8388608 contiguous values) -> 34803 us (0.964111 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11653029888 / 11619467264 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (16777216 contiguous values) -> 71159 us (0.943078 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11619475456 / 11552358400 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (256 contiguous values) -> 3 us (0.554189 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685535744 / 11684478976 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (512 contiguous values) -> 3 us (1.053980 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11684478976 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (1024 contiguous values) -> 5 us (1.468365 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11684478976 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (2048 contiguous values) -> 7 us (2.127538 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11684478976 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (4096 contiguous values) -> 10 us (3.116530 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11684478976 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (8192 contiguous values) -> 15 us (4.342463 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685535744 / 11684478976 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (16384 contiguous values) -> 25 us (5.240761 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11684478976 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (32768 contiguous values) -> 46 us (5.661749 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11684478976 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (65536 contiguous values) -> 92 us (5.679296 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11684478976 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (131072 contiguous values) -> 185 us (5.655924 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685535744 / 11684478976 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (262144 contiguous values) -> 352 us (5.956184 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11684478976 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (524288 contiguous values) -> 701 us (5.982312 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11682381824 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (1048576 contiguous values) -> 1397 us (6.001701 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11678187520 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (2097152 contiguous values) -> 2790 us (6.012470 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11678195712 / 11669798912 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (4194304 contiguous values) -> 5796 us (5.788831 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11669807104 / 11653021696 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (8388608 contiguous values) -> 14433 us (4.649589 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11653029888 / 11619467264 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (16777216 contiguous values) -> 29028 us (4.623587 GB/s assuming good implementation, i.e. 134.217728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11619475456 / 11552358400 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (256 contiguous values) -> 2 us (0.511306 GB/s assuming good implementation, i.e. 0.001024 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685535744 / 11684478976 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (512 contiguous values) -> 2 us (0.976129 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685535744 / 11684478976 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (1024 contiguous values) -> 2 us (1.636178 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685535744 / 11684478976 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (2048 contiguous values) -> 5 us (1.513645 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685535744 / 11684478976 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (4096 contiguous values) -> 8 us (2.045223 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11684478976 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (8192 contiguous values) -> 13 us (2.480848 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11684478976 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (16384 contiguous values) -> 24 us (2.666129 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685535744 / 11684478976 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (32768 contiguous values) -> 43 us (3.005773 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685543936 / 11684478976 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (65536 contiguous values) -> 79 us (3.305808 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11684478976 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (131072 contiguous values) -> 85 us (6.139093 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11684478976 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (262144 contiguous values) -> 171 us (6.107550 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11684478976 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (524288 contiguous values) -> 338 us (6.195741 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11684487168 / 11682381824 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (1048576 contiguous values) -> 686 us (6.106066 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11678187520 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (2097152 contiguous values) -> 1363 us (6.150469 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11669798912 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (4194304 contiguous values) -> 2883 us (5.819350 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11653021696 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (8388608 contiguous values) -> 7558 us (4.439178 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11653029888 / 11619467264 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (16777216 contiguous values) -> 15693 us (4.276299 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11552358400 / 12079136768
+ mpirun --bind-to none -n 2 luajit ./test/collectives.lua -all -gpu
[warning] MPI_Init_Thread only provides [warning] MPI_Init_Thread only provides 2 (asked for 3)
2 (asked for 3)
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (256 contiguous values) -> 20 us (0.050949 GB/s assuming good implementation, i.e. 0.001024 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (512 contiguous values) -> 29 us (0.070122 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (1024 contiguous values) -> 26 us (0.156323 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (2048 contiguous values) -> 26 us (0.310386 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (4096 contiguous values) -> 54 us (0.303397 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (8192 contiguous values) -> 38 us (0.853658 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (16384 contiguous values) -> 55 us (1.189433 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (32768 contiguous values) -> 89 us (1.459400 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (65536 contiguous values) -> 157 us (1.664414 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (131072 contiguous values) -> 301 us (1.737809 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (262144 contiguous values) -> 594 us (1.762885 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (524288 contiguous values) -> 1239 us (1.692598 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11685044224 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (1048576 contiguous values) -> 2533 us (1.655610 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11682947072 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (2097152 contiguous values) -> 5232 us (1.603239 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11678752768 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (4194304 contiguous values) -> 10858 us (1.545061 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11670364160 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (8388608 contiguous values) -> 40447 us (0.829582 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11653586944 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (16777216 contiguous values) -> 82843 us (0.810071 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11620032512 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (256 contiguous values) -> 34 us (0.059364 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (512 contiguous values) -> 31 us (0.130052 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (1024 contiguous values) -> 22 us (0.365529 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (2048 contiguous values) -> 26 us (0.618537 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (4096 contiguous values) -> 32 us (1.015059 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (8192 contiguous values) -> 39 us (1.639105 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (16384 contiguous values) -> 60 us (2.177251 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (32768 contiguous values) -> 90 us (2.883587 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (65536 contiguous values) -> 158 us (3.309788 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (131072 contiguous values) -> 293 us (3.572743 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (262144 contiguous values) -> 557 us (3.762391 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (524288 contiguous values) -> 1087 us (3.855737 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11685044224 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (1048576 contiguous values) -> 2148 us (3.903823 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11682947072 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (2097152 contiguous values) -> 4279 us (3.920548 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11678752768 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (4194304 contiguous values) -> 8735 us (3.841330 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11670364160 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (8388608 contiguous values) -> 20614 us (3.255405 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11653586944 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (16777216 contiguous values) -> 41887 us (3.204260 GB/s assuming good implementation, i.e. 134.217728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11620032512 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (256 contiguous values) -> 47 us (0.021648 GB/s assuming good implementation, i.e. 0.001024 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (512 contiguous values) -> 28 us (0.072367 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (1024 contiguous values) -> 22 us (0.181990 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (2048 contiguous values) -> 23 us (0.354590 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (4096 contiguous values) -> 28 us (0.570760 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (8192 contiguous values) -> 37 us (0.878204 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (16384 contiguous values) -> 55 us (1.182779 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (32768 contiguous values) -> 88 us (1.477838 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (65536 contiguous values) -> 144 us (1.809002 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (131072 contiguous values) -> 193 us (2.715179 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (262144 contiguous values) -> 367 us (2.854021 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (524288 contiguous values) -> 708 us (2.961249 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11685044224 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (1048576 contiguous values) -> 1398 us (2.998089 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11682947072 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (2097152 contiguous values) -> 2774 us (3.023154 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11678752768 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (4194304 contiguous values) -> 5675 us (2.956123 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11670364160 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (8388608 contiguous values) -> 13586 us (2.469690 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11653586944 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (16777216 contiguous values) -> 27670 us (2.425321 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11620032512 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (256 contiguous values) -> 32 us (0.031909 GB/s assuming good implementation, i.e. 0.001024 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11685801984 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (512 contiguous values) -> 11 us (0.179706 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (1024 contiguous values) -> 13 us (0.310106 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (2048 contiguous values) -> 14 us (0.553297 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (4096 contiguous values) -> 17 us (0.931158 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (8192 contiguous values) -> 23 us (1.418359 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (16384 contiguous values) -> 34 us (1.911529 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (32768 contiguous values) -> 61 us (2.134974 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (65536 contiguous values) -> 113 us (2.315736 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (131072 contiguous values) -> 210 us (2.488146 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (262144 contiguous values) -> 399 us (2.625386 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (524288 contiguous values) -> 834 us (2.513026 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11684753408 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (1048576 contiguous values) -> 1709 us (2.453103 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11682656256 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (2097152 contiguous values) -> 3515 us (2.386109 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11678461952 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (4194304 contiguous values) -> 7847 us (2.137906 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11670073344 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (8388608 contiguous values) -> 35209 us (0.953007 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11653296128 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (16777216 contiguous values) -> 70837 us (0.947365 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11619741696 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (256 contiguous values) -> 24 us (0.084630 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (512 contiguous values) -> 11 us (0.369460 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (1024 contiguous values) -> 13 us (0.625860 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (2048 contiguous values) -> 15 us (1.077108 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (4096 contiguous values) -> 18 us (1.771121 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (8192 contiguous values) -> 23 us (2.765371 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (16384 contiguous values) -> 34 us (3.823059 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (32768 contiguous values) -> 55 us (4.704799 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (65536 contiguous values) -> 103 us (5.065707 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (131072 contiguous values) -> 195 us (5.368709 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (262144 contiguous values) -> 362 us (5.785000 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (524288 contiguous values) -> 708 us (5.920903 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11684753408 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (1048576 contiguous values) -> 1405 us (5.969220 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11682656256 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (2097152 contiguous values) -> 2795 us (6.001087 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11678461952 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (4194304 contiguous values) -> 5804 us (5.780462 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11670073344 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (8388608 contiguous values) -> 14271 us (4.702331 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11653296128 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (16777216 contiguous values) -> 29134 us (4.606818 GB/s assuming good implementation, i.e. 134.217728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11619741696 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (256 contiguous values) -> 16 us (0.060238 GB/s assuming good implementation, i.e. 0.001024 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (512 contiguous values) -> 8 us (0.246837 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (1024 contiguous values) -> 8 us (0.460586 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (2048 contiguous values) -> 12 us (0.660764 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (4096 contiguous values) -> 15 us (1.057223 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (8192 contiguous values) -> 21 us (1.510318 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (16384 contiguous values) -> 33 us (1.963414 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (32768 contiguous values) -> 55 us (2.377837 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (65536 contiguous values) -> 87 us (2.982131 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (131072 contiguous values) -> 98 us (5.306523 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (262144 contiguous values) -> 177 us (5.891556 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (524288 contiguous values) -> 345 us (6.062926 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11684753408 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (1048576 contiguous values) -> 686 us (6.114130 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11682656256 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (2097152 contiguous values) -> 1358 us (6.176706 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11678461952 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (4194304 contiguous values) -> 2922 us (5.740872 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11670073344 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (8388608 contiguous values) -> 7436 us (4.511945 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11653296128 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (16777216 contiguous values) -> 15618 us (4.296751 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11619741696 / 12079136768
+ for nproc in '$(echo "2 4 8" | tr " " "\n")'
+ mpirun --bind-to none -n 4 luajit ./test/collectives.lua -all
[warning] MPI_Init_Thread only provides [warning] MPI_Init_Thread only provides 2 (asked for 3)
[warning] MPI_Init_Thread only provides 2 (asked for 3)
[warning] MPI_Init_Thread only provides 2 (asked for 3)
2 (asked for 3)
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (256 contiguous values) -> 8 us (0.126323 GB/s assuming good implementation, i.e. 0.001024 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (512 contiguous values) -> 8 us (0.243341 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (1024 contiguous values) -> 15 us (0.260696 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (2048 contiguous values) -> 14 us (0.580401 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (4096 contiguous values) -> 34 us (0.472299 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (8192 contiguous values) -> 15 us (2.114445 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (16384 contiguous values) -> 27 us (2.400680 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (32768 contiguous values) -> 56 us (2.328487 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (65536 contiguous values) -> 108 us (2.406987 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (131072 contiguous values) -> 194 us (2.695873 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (262144 contiguous values) -> 405 us (2.588457 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (524288 contiguous values) -> 858 us (2.443970 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (1048576 contiguous values) -> 1771 us (2.367787 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (2097152 contiguous values) -> 3905 us (2.147785 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (4194304 contiguous values) -> 8890 us (1.887138 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (8388608 contiguous values) -> 31886 us (1.052315 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (16777216 contiguous values) -> 63175 us (1.062268 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (256 contiguous values) -> 16 us (0.123419 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (512 contiguous values) -> 13 us (0.310667 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (1024 contiguous values) -> 8 us (0.911399 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (2048 contiguous values) -> 13 us (1.205605 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (4096 contiguous values) -> 20 us (1.630355 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (8192 contiguous values) -> 30 us (2.149163 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (16384 contiguous values) -> 45 us (2.849952 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (32768 contiguous values) -> 79 us (3.297875 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (65536 contiguous values) -> 168 us (3.102459 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (131072 contiguous values) -> 335 us (3.121617 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (262144 contiguous values) -> 616 us (3.401691 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (524288 contiguous values) -> 1161 us (3.609838 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (1048576 contiguous values) -> 2280 us (3.678565 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (2097152 contiguous values) -> 4648 us (3.609320 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (4194304 contiguous values) -> 11285 us (2.973235 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (8388608 contiguous values) -> 23113 us (2.903510 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (16777216 contiguous values) -> 46200 us (2.905109 GB/s assuming good implementation, i.e. 134.217728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (256 contiguous values) -> 27 us (0.074501 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (512 contiguous values) -> 10 us (0.393132 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (1024 contiguous values) -> 5 us (1.547736 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (2048 contiguous values) -> 9 us (1.726620 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (4096 contiguous values) -> 14 us (2.199023 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (8192 contiguous values) -> 24 us (2.640518 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (16384 contiguous values) -> 46 us (2.836717 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (32768 contiguous values) -> 86 us (3.040685 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (65536 contiguous values) -> 163 us (3.210253 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (131072 contiguous values) -> 272 us (3.852191 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (262144 contiguous values) -> 545 us (3.842935 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (524288 contiguous values) -> 650 us (6.449931 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (1048576 contiguous values) -> 1291 us (6.493259 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (2097152 contiguous values) -> 2562 us (6.546417 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (4194304 contiguous values) -> 6660 us (5.037746 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (8388608 contiguous values) -> 14250 us (4.709326 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (16777216 contiguous values) -> 29459 us (4.555979 GB/s assuming good implementation, i.e. 134.217728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (256 contiguous values) -> 3 us (0.261888 GB/s assuming good implementation, i.e. 0.001024 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11348058112 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (512 contiguous values) -> 6 us (0.297230 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11352285184 / 11348058112 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (1024 contiguous values) -> 8 us (0.475897 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11351228416 / 11348058112 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (2048 contiguous values) -> 12 us (0.672402 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11352285184 / 11348058112 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (4096 contiguous values) -> 14 us (1.106594 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11352285184 / 11348058112 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (8192 contiguous values) -> 15 us (2.114445 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11349114880 / 11348058112 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (16384 contiguous values) -> 30 us (2.169518 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11350179840 / 11348058112 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (32768 contiguous values) -> 55 us (2.370659 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11351228416 / 11348058112 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (65536 contiguous values) -> 101 us (2.593188 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11351236608 / 11348058112 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (131072 contiguous values) -> 196 us (2.668070 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11350171648 / 11348058112 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (262144 contiguous values) -> 412 us (2.538995 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11351228416 / 11348058112 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (524288 contiguous values) -> 858 us (2.441392 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11350179840 / 11343863808 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (1048576 contiguous values) -> 1788 us (2.344624 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11352285184 / 11335475200 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (2097152 contiguous values) -> 3955 us (2.120856 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11335491584 / 11318697984 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (4194304 contiguous values) -> 9820 us (1.708440 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11318722560 / 11285143552 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (8388608 contiguous values) -> 32607 us (1.029041 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11318722560 / 11218034688 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (16777216 contiguous values) -> 63936 us (1.049619 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11150934016 / 11083816960 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (256 contiguous values) -> 5 us (0.378411 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11352285184 / 11348058112 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (512 contiguous values) -> 6 us (0.660764 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11351236608 / 11348058112 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (1024 contiguous values) -> 8 us (0.911399 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11351228416 / 11348058112 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (2048 contiguous values) -> 20 us (0.811328 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11351228416 / 11348058112 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (4096 contiguous values) -> 25 us (1.310190 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11351228416 / 11348058112 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (8192 contiguous values) -> 35 us (1.862316 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11351228416 / 11348058112 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (16384 contiguous values) -> 50 us (2.610426 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11351228416 / 11348058112 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (32768 contiguous values) -> 84 us (3.094601 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11351228416 / 11348058112 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (65536 contiguous values) -> 160 us (3.274793 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11350179840 / 11348058112 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (131072 contiguous values) -> 337 us (3.104211 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11351236608 / 11348058112 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (262144 contiguous values) -> 596 us (3.515765 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11350179840 / 11348058112 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (524288 contiguous values) -> 1137 us (3.687316 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11352285184 / 11343863808 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (1048576 contiguous values) -> 2197 us (3.816962 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11343888384 / 11335475200 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (2097152 contiguous values) -> 4662 us (3.598651 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11343888384 / 11318697984 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (4194304 contiguous values) -> 10892 us (3.080647 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11301928960 / 11285143552 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (8388608 contiguous values) -> 22491 us (2.983743 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11285168128 / 11218034688 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (16777216 contiguous values) -> 44915 us (2.988214 GB/s assuming good implementation, i.e. 134.217728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11285168128 / 11083816960 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (256 contiguous values) -> 3 us (0.617981 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11349114880 / 11348058112 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (512 contiguous values) -> 3 us (1.047553 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11349123072 / 11348058112 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (1024 contiguous values) -> 5 us (1.547736 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11349123072 / 11348066304 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (2048 contiguous values) -> 10 us (1.590729 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11350171648 / 11348058112 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (4096 contiguous values) -> 14 us (2.306023 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11350179840 / 11348058112 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (8192 contiguous values) -> 26 us (2.474149 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11350179840 / 11348058112 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (16384 contiguous values) -> 45 us (2.893452 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11351228416 / 11348058112 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (32768 contiguous values) -> 83 us (3.151366 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11350171648 / 11348058112 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (65536 contiguous values) -> 159 us (3.287030 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11350179840 / 11348058112 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (131072 contiguous values) -> 262 us (3.991692 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11350179840 / 11348058112 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (262144 contiguous values) -> 509 us (4.118407 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11351228416 / 11348058112 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (524288 contiguous values) -> 643 us (6.519971 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11350188032 / 11343863808 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (1048576 contiguous values) -> 1279 us (6.554099 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11339677696 / 11335475200 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (2097152 contiguous values) -> 2592 us (6.471701 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11343888384 / 11318697984 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (4194304 contiguous values) -> 6802 us (4.932515 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11335499776 / 11285143552 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (8388608 contiguous values) -> 14483 us (4.633600 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11318722560 / 11218034688 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (16777216 contiguous values) -> 29302 us (4.580374 GB/s assuming good implementation, i.e. 134.217728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11285168128 / 11083816960 / 12079136768
+ mpirun --bind-to none -n 4 luajit ./test/collectives.lua -all -gpu
[warning] MPI_Init_Thread only provides 2 (asked for 3)[warning] MPI_Init_Thread only provides 2 (asked for 3)
[warning] MPI_Init_Thread only provides 2 (asked for 3)
[warning] MPI_Init_Thread only provides 2 (asked for 3)

sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (256 contiguous values) -> 20 us (0.048806 GB/s assuming good implementation, i.e. 0.001024 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (512 contiguous values) -> 35 us (0.057689 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (1024 contiguous values) -> 41 us (0.098003 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (2048 contiguous values) -> 48 us (0.169260 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (4096 contiguous values) -> 43 us (0.376752 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (8192 contiguous values) -> 46 us (0.700147 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (16384 contiguous values) -> 65 us (1.003570 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (32768 contiguous values) -> 106 us (1.234020 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (65536 contiguous values) -> 196 us (1.334845 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (131072 contiguous values) -> 371 us (1.410173 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (262144 contiguous values) -> 652 us (1.607062 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (524288 contiguous values) -> 1387 us (1.511148 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11351285760 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (1048576 contiguous values) -> 2824 us (1.485074 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11349188608 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (2097152 contiguous values) -> 5366 us (1.563083 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11344994304 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (4194304 contiguous values) -> 14932 us (1.123500 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11336605696 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (8388608 contiguous values) -> 39133 us (0.857439 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11319828480 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (16777216 contiguous values) -> 79190 us (0.847439 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11286274048 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (256 contiguous values) -> 48 us (0.042149 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (512 contiguous values) -> 41 us (0.099651 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (1024 contiguous values) -> 25 us (0.316388 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (2048 contiguous values) -> 32 us (0.510546 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (4096 contiguous values) -> 43 us (0.751854 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (8192 contiguous values) -> 60 us (1.090353 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (16384 contiguous values) -> 90 us (1.441793 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (32768 contiguous values) -> 146 us (1.784632 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (65536 contiguous values) -> 268 us (1.956252 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (131072 contiguous values) -> 511 us (2.049129 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (262144 contiguous values) -> 949 us (2.209130 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (524288 contiguous values) -> 1818 us (2.306476 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11351285760 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (1048576 contiguous values) -> 3587 us (2.338422 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11349188608 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (2097152 contiguous values) -> 7449 us (2.252182 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11344994304 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (4194304 contiguous values) -> 16599 us (2.021437 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11336605696 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (8388608 contiguous values) -> 34032 us (1.971905 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11319828480 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (16777216 contiguous values) -> 68844 us (1.949578 GB/s assuming good implementation, i.e. 134.217728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11286274048 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (256 contiguous values) -> 40 us (0.050798 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (512 contiguous values) -> 25 us (0.159368 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (1024 contiguous values) -> 21 us (0.386499 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (2048 contiguous values) -> 26 us (0.620772 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (4096 contiguous values) -> 35 us (0.925515 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (8192 contiguous values) -> 54 us (1.207193 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (16384 contiguous values) -> 80 us (1.634233 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (32768 contiguous values) -> 138 us (1.898328 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (65536 contiguous values) -> 240 us (2.184388 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (131072 contiguous values) -> 406 us (2.582074 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (262144 contiguous values) -> 783 us (2.677002 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (524288 contiguous values) -> 1262 us (3.321976 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11351285760 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (1048576 contiguous values) -> 2589 us (3.239217 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11349188608 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (2097152 contiguous values) -> 5261 us (3.188564 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11344994304 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (4194304 contiguous values) -> 12444 us (2.696430 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11336605696 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (8388608 contiguous values) -> 26120 us (2.569182 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11319828480 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (16777216 contiguous values) -> 52750 us (2.544393 GB/s assuming good implementation, i.e. 134.217728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11286274048 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (256 contiguous values) -> 31 us (0.032390 GB/s assuming good implementation, i.e. 0.001024 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352027136 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (512 contiguous values) -> 11 us (0.172143 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (1024 contiguous values) -> 16 us (0.251168 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (2048 contiguous values) -> 16 us (0.506034 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (4096 contiguous values) -> 24 us (0.660129 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (8192 contiguous values) -> 24 us (1.336955 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (16384 contiguous values) -> 36 us (1.786081 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (32768 contiguous values) -> 71 us (1.833130 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (65536 contiguous values) -> 109 us (2.402779 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (131072 contiguous values) -> 207 us (2.530230 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (262144 contiguous values) -> 415 us (2.524276 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (524288 contiguous values) -> 894 us (2.344749 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11350978560 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (1048576 contiguous values) -> 1819 us (2.305449 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11348881408 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (2097152 contiguous values) -> 4053 us (2.069620 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11344687104 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (4194304 contiguous values) -> 9797 us (1.712485 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11336298496 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (8388608 contiguous values) -> 32447 us (1.034101 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11319521280 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (16777216 contiguous values) -> 64180 us (1.045621 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11285966848 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (256 contiguous values) -> 32 us (0.063208 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (512 contiguous values) -> 14 us (0.288253 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (1024 contiguous values) -> 18 us (0.452102 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (2048 contiguous values) -> 21 us (0.766103 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (4096 contiguous values) -> 28 us (1.166714 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (8192 contiguous values) -> 38 us (1.697825 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (16384 contiguous values) -> 54 us (2.400680 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (32768 contiguous values) -> 90 us (2.887373 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (65536 contiguous values) -> 182 us (2.869664 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (131072 contiguous values) -> 345 us (3.033345 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (262144 contiguous values) -> 603 us (3.472599 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (524288 contiguous values) -> 1137 us (3.687316 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11350978560 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (1048576 contiguous values) -> 2202 us (3.809193 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11348881408 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (2097152 contiguous values) -> 4788 us (3.503722 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11344687104 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (4194304 contiguous values) -> 10890 us (3.081213 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11336298496 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (8388608 contiguous values) -> 22431 us (2.991671 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11319521280 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (16777216 contiguous values) -> 44751 us (2.999178 GB/s assuming good implementation, i.e. 134.217728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11285966848 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (256 contiguous values) -> 17 us (0.118319 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (512 contiguous values) -> 11 us (0.359411 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (1024 contiguous values) -> 11 us (0.732617 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353100288 / 11352035328 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (2048 contiguous values) -> 16 us (1.018066 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353100288 / 11352027136 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (4096 contiguous values) -> 21 us (1.539070 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (8192 contiguous values) -> 32 us (2.010811 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (16384 contiguous values) -> 54 us (2.404881 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (32768 contiguous values) -> 91 us (2.855874 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (65536 contiguous values) -> 163 us (3.214476 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (131072 contiguous values) -> 266 us (3.933148 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (262144 contiguous values) -> 507 us (4.128264 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (524288 contiguous values) -> 654 us (6.408344 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11350978560 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (1048576 contiguous values) -> 1297 us (6.466646 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11348881408 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (2097152 contiguous values) -> 2623 us (6.395938 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11344687104 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (4194304 contiguous values) -> 6912 us (4.854456 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11336298496 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (8388608 contiguous values) -> 14566 us (4.607131 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11319521280 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (16777216 contiguous values) -> 29167 us (4.601697 GB/s assuming good implementation, i.e. 134.217728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11285966848 / 12079136768
+ for nproc in '$(echo "2 4 8" | tr " " "\n")'
+ mpirun --bind-to none -n 8 luajit ./test/collectives.lua -all
[warning] MPI_Init_Thread only provides 2 (asked for 3)
[warning] MPI_Init_Thread only provides 2 (asked for 3)
[warning] MPI_Init_Thread only provides 2 (asked for 3)
[warning] MPI_Init_Thread only provides 2 (asked for 3)
[warning] MPI_Init_Thread only provides 2 (asked for 3)
[warning] MPI_Init_Thread only provides 2 (asked for 3)
[warning] MPI_Init_Thread only provides 2 (asked for 3)
[warning] MPI_Init_Thread only provides 2 (asked for 3)
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (256 contiguous values) -> 469 us (0.002181 GB/s assuming good implementation, i.e. 0.001024 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (512 contiguous values) -> 14 us (0.143166 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (1024 contiguous values) -> 30 us (0.135168 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (2048 contiguous values) -> 26 us (0.311230 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (4096 contiguous values) -> 36 us (0.447392 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (8192 contiguous values) -> 21 us (1.544258 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (16384 contiguous values) -> 37 us (1.729880 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (32768 contiguous values) -> 65 us (2.001295 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (65536 contiguous values) -> 108 us (2.409624 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (131072 contiguous values) -> 218 us (2.401729 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (262144 contiguous values) -> 457 us (2.291485 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (524288 contiguous values) -> 901 us (2.326578 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (1048576 contiguous values) -> 2539 us (1.651492 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (2097152 contiguous values) -> 6267 us (1.338343 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (4194304 contiguous values) -> 13419 us (1.250213 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (8388608 contiguous values) -> 41570 us (0.807162 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (16777216 contiguous values) -> 83548 us (0.803229 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (256 contiguous values) -> 22 us (0.091773 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (512 contiguous values) -> 17 us (0.229985 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (1024 contiguous values) -> 12 us (0.633944 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (2048 contiguous values) -> 18 us (0.891303 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (4096 contiguous values) -> 29 us (1.099512 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (8192 contiguous values) -> 43 us (1.523713 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (16384 contiguous values) -> 68 us (1.916193 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (32768 contiguous values) -> 105 us (2.475263 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (65536 contiguous values) -> 200 us (2.609807 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (131072 contiguous values) -> 396 us (2.641945 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (262144 contiguous values) -> 768 us (2.729248 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (524288 contiguous values) -> 1519 us (2.759948 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (1048576 contiguous values) -> 3148 us (2.664554 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (2097152 contiguous values) -> 7820 us (2.145232 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (4194304 contiguous values) -> 15478 us (2.167810 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (8388608 contiguous values) -> 32503 us (2.064679 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (16777216 contiguous values) -> 64921 us (2.067391 GB/s assuming good implementation, i.e. 134.217728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (256 contiguous values) -> 35 us (0.087237 GB/s assuming good implementation, i.e. 0.003072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (512 contiguous values) -> 9 us (0.645860 GB/s assuming good implementation, i.e. 0.006144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (1024 contiguous values) -> 6 us (1.944891 GB/s assuming good implementation, i.e. 0.012288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (2048 contiguous values) -> 12 us (1.952258 GB/s assuming good implementation, i.e. 0.024576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (4096 contiguous values) -> 40 us (1.213410 GB/s assuming good implementation, i.e. 0.049152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (8192 contiguous values) -> 49 us (1.989946 GB/s assuming good implementation, i.e. 0.098304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (16384 contiguous values) -> 56 us (3.486823 GB/s assuming good implementation, i.e. 0.196608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (32768 contiguous values) -> 102 us (3.817749 GB/s assuming good implementation, i.e. 0.393216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (65536 contiguous values) -> 242 us (3.241803 GB/s assuming good implementation, i.e. 0.786432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (131072 contiguous values) -> 324 us (4.854356 GB/s assuming good implementation, i.e. 1.572864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (262144 contiguous values) -> 617 us (5.091903 GB/s assuming good implementation, i.e. 3.145728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (524288 contiguous values) -> 1223 us (5.141008 GB/s assuming good implementation, i.e. 6.291456 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (1048576 contiguous values) -> 1362 us (9.236521 GB/s assuming good implementation, i.e. 12.582912 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (2097152 contiguous values) -> 3513 us (7.163234 GB/s assuming good implementation, i.e. 25.165824 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (4194304 contiguous values) -> 7195 us (6.995183 GB/s assuming good implementation, i.e. 50.331648 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (8388608 contiguous values) -> 15003 us (6.709187 GB/s assuming good implementation, i.e. 100.663296 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (16777216 contiguous values) -> 29996 us (6.711714 GB/s assuming good implementation, i.e. 201.326592 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (256 contiguous values) -> 164 us (0.006213 GB/s assuming good implementation, i.e. 0.001024 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10683752448 / 10675216384 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (512 contiguous values) -> 4 us (0.477219 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10681556992 / 10675216384 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (1024 contiguous values) -> 6 us (0.638657 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10682613760 / 10675216384 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (2048 contiguous values) -> 93 us (0.087787 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10681565184 / 10675216384 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (4096 contiguous values) -> 98 us (0.166673 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10681565184 / 10675216384 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (8192 contiguous values) -> 17 us (1.916861 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10681565184 / 10675216384 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (16384 contiguous values) -> 124 us (0.525981 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10682613760 / 10675216384 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (32768 contiguous values) -> 143 us (0.910795 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10679468032 / 10675216384 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (65536 contiguous values) -> 110 us (2.374242 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10679459840 / 10675216384 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (131072 contiguous values) -> 259 us (2.021904 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10681565184 / 10675216384 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (262144 contiguous values) -> 535 us (1.958081 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10683670528 / 10675216384 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (524288 contiguous values) -> 1062 us (1.974121 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10681565184 / 10666827776 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (1048576 contiguous values) -> 2928 us (1.432378 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10679468032 / 10650050560 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (2097152 contiguous values) -> 6885 us (1.218283 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10675273728 / 10616496128 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (4194304 contiguous values) -> 13920 us (1.205198 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10666893312 / 10549387264 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (8388608 contiguous values) -> 40672 us (0.825000 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10650107904 / 10415169536 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (16777216 contiguous values) -> 79311 us (0.846145 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10515881984 / 10146734080 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (256 contiguous values) -> 8 us (0.240614 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10279911424 / 10675216384 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (512 contiguous values) -> 8 us (0.470681 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10678411264 / 10675216384 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (1024 contiguous values) -> 13 us (0.625860 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10681565184 / 10675216384 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (2048 contiguous values) -> 18 us (0.866576 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10681565184 / 10675216384 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (4096 contiguous values) -> 26 us (1.241544 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10682613760 / 10675216384 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (8192 contiguous values) -> 50 us (1.289901 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10681565184 / 10675216384 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (16384 contiguous values) -> 72 us (1.817976 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10680516608 / 10675216384 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (32768 contiguous values) -> 107 us (2.434163 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10681565184 / 10675216384 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (65536 contiguous values) -> 208 us (2.508582 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10680508416 / 10675216384 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (131072 contiguous values) -> 408 us (2.565057 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10681565184 / 10675216384 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (262144 contiguous values) -> 804 us (2.608104 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10681565184 / 10675216384 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (524288 contiguous values) -> 1517 us (2.763200 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10679468032 / 10666827776 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (1048576 contiguous values) -> 3155 us (2.658333 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10671079424 / 10650050560 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (2097152 contiguous values) -> 7699 us (2.179058 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10658496512 / 10616496128 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (4194304 contiguous values) -> 15444 us (2.172512 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10666885120 / 10549387264 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (8388608 contiguous values) -> 32106 us (2.090183 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10616553472 / 10415169536 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (16777216 contiguous values) -> 64356 us (2.085535 GB/s assuming good implementation, i.e. 134.217728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10415226880 / 10146734080 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (256 contiguous values) -> 4 us (0.766958 GB/s assuming good implementation, i.e. 0.003072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10679451648 / 10675216384 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (512 contiguous values) -> 5 us (1.227134 GB/s assuming good implementation, i.e. 0.006144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10680500224 / 10675216384 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (1024 contiguous values) -> 5 us (2.112279 GB/s assuming good implementation, i.e. 0.012288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10679468032 / 10676273152 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (2048 contiguous values) -> 11 us (2.193175 GB/s assuming good implementation, i.e. 0.024576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10679451648 / 10675216384 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (4096 contiguous values) -> 17 us (2.759818 GB/s assuming good implementation, i.e. 0.049152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10680516608 / 10675216384 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (8192 contiguous values) -> 30 us (3.203705 GB/s assuming good implementation, i.e. 0.098304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10680516608 / 10675216384 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (16384 contiguous values) -> 56 us (3.473605 GB/s assuming good implementation, i.e. 0.196608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10679468032 / 10675216384 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (32768 contiguous values) -> 106 us (3.709553 GB/s assuming good implementation, i.e. 0.393216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10682613760 / 10675216384 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (65536 contiguous values) -> 213 us (3.688811 GB/s assuming good implementation, i.e. 0.786432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10682613760 / 10675216384 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (131072 contiguous values) -> 326 us (4.814325 GB/s assuming good implementation, i.e. 1.572864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10680516608 / 10675216384 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (262144 contiguous values) -> 637 us (4.936079 GB/s assuming good implementation, i.e. 3.145728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10682613760 / 10675216384 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (524288 contiguous values) -> 1342 us (4.688083 GB/s assuming good implementation, i.e. 6.291456 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10681565184 / 10666827776 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (1048576 contiguous values) -> 1429 us (8.804898 GB/s assuming good implementation, i.e. 12.582912 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10675273728 / 10650050560 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (2097152 contiguous values) -> 3877 us (6.489387 GB/s assuming good implementation, i.e. 25.165824 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10650099712 / 10616496128 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (4194304 contiguous values) -> 8027 us (6.269992 GB/s assuming good implementation, i.e. 50.331648 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10666885120 / 10549387264 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (8388608 contiguous values) -> 16042 us (6.274595 GB/s assuming good implementation, i.e. 100.663296 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10549444608 / 10415169536 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (16777216 contiguous values) -> 32206 us (6.251101 GB/s assuming good implementation, i.e. 201.326592 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10415210496 / 10146734080 / 12079136768
+ mpirun --bind-to none -n 8 luajit ./test/collectives.lua -all -gpu
[warning] MPI_Init_Thread only provides 2 (asked for 3)[warning] MPI_Init_Thread only provides 2 (asked for 3)[warning] MPI_Init_Thread only provides 2 (asked for 3)
[warning] MPI_Init_Thread only provides 2 (asked for 3)
[warning] MPI_Init_Thread only provides 2 (asked for 3)
[warning] MPI_Init_Thread only provides 2 (asked for 3)
[warning] MPI_Init_Thread only provides 2 (asked for 3)

[warning] MPI_Init_Thread only provides 2 (asked for 3)

sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (256 contiguous values) -> 185 us (0.005521 GB/s assuming good implementation, i.e. 0.001024 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (512 contiguous values) -> 110 us (0.018569 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (1024 contiguous values) -> 40 us (0.100174 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (2048 contiguous values) -> 49 us (0.164874 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (4096 contiguous values) -> 50 us (0.323234 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (8192 contiguous values) -> 55 us (0.589361 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (16384 contiguous values) -> 84 us (0.779353 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (32768 contiguous values) -> 118 us (1.108826 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (65536 contiguous values) -> 201 us (1.302893 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (131072 contiguous values) -> 400 us (1.310659 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (262144 contiguous values) -> 836 us (1.253219 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (524288 contiguous values) -> 1705 us (1.229862 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10683768832 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (1048576 contiguous values) -> 3360 us (1.248195 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10681671680 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (2097152 contiguous values) -> 9501 us (0.882852 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10677477376 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (4194304 contiguous values) -> 17512 us (0.958003 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10669088768 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (8388608 contiguous values) -> 52589 us (0.638049 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10652311552 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (16777216 contiguous values) -> 100787 us (0.665848 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10618757120 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (256 contiguous values) -> 55 us (0.037090 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (512 contiguous values) -> 34 us (0.117349 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (1024 contiguous values) -> 32 us (0.255273 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (2048 contiguous values) -> 43 us (0.378411 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (4096 contiguous values) -> 58 us (0.558241 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (8192 contiguous values) -> 89 us (0.731447 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (16384 contiguous values) -> 139 us (0.936871 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (32768 contiguous values) -> 217 us (1.202967 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (65536 contiguous values) -> 389 us (1.347028 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (131072 contiguous values) -> 754 us (1.390511 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (262144 contiguous values) -> 1470 us (1.426432 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (524288 contiguous values) -> 2856 us (1.468132 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10683768832 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (1048576 contiguous values) -> 5960 us (1.407319 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10681671680 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (2097152 contiguous values) -> 16395 us (1.023274 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10677477376 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (4194304 contiguous values) -> 28309 us (1.185255 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10669088768 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (8388608 contiguous values) -> 56054 us (1.197208 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10652311552 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (16777216 contiguous values) -> 111210 us (1.206877 GB/s assuming good implementation, i.e. 134.217728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10618757120 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (256 contiguous values) -> 50 us (0.060351 GB/s assuming good implementation, i.e. 0.003072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (512 contiguous values) -> 28 us (0.213326 GB/s assuming good implementation, i.e. 0.006144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (1024 contiguous values) -> 26 us (0.461824 GB/s assuming good implementation, i.e. 0.012288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (2048 contiguous values) -> 53 us (0.457723 GB/s assuming good implementation, i.e. 0.024576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (4096 contiguous values) -> 64 us (0.766958 GB/s assuming good implementation, i.e. 0.049152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (8192 contiguous values) -> 81 us (1.204548 GB/s assuming good implementation, i.e. 0.098304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (16384 contiguous values) -> 125 us (1.571629 GB/s assuming good implementation, i.e. 0.196608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (32768 contiguous values) -> 219 us (1.791319 GB/s assuming good implementation, i.e. 0.393216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (65536 contiguous values) -> 377 us (2.084382 GB/s assuming good implementation, i.e. 0.786432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (131072 contiguous values) -> 653 us (2.407163 GB/s assuming good implementation, i.e. 1.572864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (262144 contiguous values) -> 1276 us (2.464352 GB/s assuming good implementation, i.e. 3.145728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (524288 contiguous values) -> 2506 us (2.509656 GB/s assuming good implementation, i.e. 6.291456 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10683768832 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (1048576 contiguous values) -> 4004 us (3.142509 GB/s assuming good implementation, i.e. 12.582912 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10681671680 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (2097152 contiguous values) -> 9254 us (2.719306 GB/s assuming good implementation, i.e. 25.165824 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10677477376 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (4194304 contiguous values) -> 19567 us (2.572248 GB/s assuming good implementation, i.e. 50.331648 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10669088768 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (8388608 contiguous values) -> 39454 us (2.551370 GB/s assuming good implementation, i.e. 100.663296 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10652311552 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (16777216 contiguous values) -> 79499 us (2.532426 GB/s assuming good implementation, i.e. 201.326592 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10618757120 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (256 contiguous values) -> 30 us (0.033450 GB/s assuming good implementation, i.e. 0.001024 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684477440 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (512 contiguous values) -> 11 us (0.174948 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (1024 contiguous values) -> 18 us (0.221676 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (2048 contiguous values) -> 17 us (0.465579 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (4096 contiguous values) -> 33 us (0.481904 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (8192 contiguous values) -> 27 us (1.200340 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (16384 contiguous values) -> 46 us (1.418359 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (32768 contiguous values) -> 71 us (1.841111 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (65536 contiguous values) -> 119 us (2.188083 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (131072 contiguous values) -> 218 us (2.400680 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (262144 contiguous values) -> 471 us (2.222920 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (524288 contiguous values) -> 988 us (2.122609 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10683428864 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (1048576 contiguous values) -> 2697 us (1.554945 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10681331712 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (2097152 contiguous values) -> 6631 us (1.264929 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10677137408 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (4194304 contiguous values) -> 13580 us (1.235391 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10668748800 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (8388608 contiguous values) -> 41565 us (0.807270 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10651987968 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (16777216 contiguous values) -> 79058 us (0.848856 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10618417152 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (256 contiguous values) -> 38 us (0.053620 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (512 contiguous values) -> 18 us (0.227548 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (1024 contiguous values) -> 23 us (0.353132 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (2048 contiguous values) -> 28 us (0.568870 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (4096 contiguous values) -> 41 us (0.788067 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (8192 contiguous values) -> 56 us (1.159822 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (16384 contiguous values) -> 83 us (1.564028 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (32768 contiguous values) -> 123 us (2.125893 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (65536 contiguous values) -> 222 us (2.357443 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (131072 contiguous values) -> 412 us (2.545019 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (262144 contiguous values) -> 783 us (2.675618 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (524288 contiguous values) -> 1452 us (2.887231 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10683428864 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (1048576 contiguous values) -> 3006 us (2.790063 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10681331712 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (2097152 contiguous values) -> 7683 us (2.183649 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10677137408 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (4194304 contiguous values) -> 15424 us (2.175383 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10668748800 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (8388608 contiguous values) -> 32266 us (2.079805 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10651971584 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (16777216 contiguous values) -> 64697 us (2.074559 GB/s assuming good implementation, i.e. 134.217728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10618417152 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (256 contiguous values) -> 20 us (0.152846 GB/s assuming good implementation, i.e. 0.003072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (512 contiguous values) -> 12 us (0.483486 GB/s assuming good implementation, i.e. 0.006144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (1024 contiguous values) -> 15 us (0.807831 GB/s assuming good implementation, i.e. 0.012288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685583360 / 10684485632 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (2048 contiguous values) -> 20 us (1.193046 GB/s assuming good implementation, i.e. 0.024576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685583360 / 10684477440 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (4096 contiguous values) -> 28 us (1.730969 GB/s assuming good implementation, i.e. 0.049152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (8192 contiguous values) -> 41 us (2.386093 GB/s assuming good implementation, i.e. 0.098304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (16384 contiguous values) -> 85 us (2.312489 GB/s assuming good implementation, i.e. 0.196608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (32768 contiguous values) -> 126 us (3.113588 GB/s assuming good implementation, i.e. 0.393216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (65536 contiguous values) -> 232 us (3.376878 GB/s assuming good implementation, i.e. 0.786432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (131072 contiguous values) -> 374 us (4.205437 GB/s assuming good implementation, i.e. 1.572864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (262144 contiguous values) -> 704 us (4.463360 GB/s assuming good implementation, i.e. 3.145728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (524288 contiguous values) -> 1352 us (4.652376 GB/s assuming good implementation, i.e. 6.291456 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10683428864 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (1048576 contiguous values) -> 1344 us (9.360865 GB/s assuming good implementation, i.e. 12.582912 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10681331712 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (2097152 contiguous values) -> 3708 us (6.785800 GB/s assuming good implementation, i.e. 25.165824 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10677137408 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (4194304 contiguous values) -> 7730 us (6.510862 GB/s assuming good implementation, i.e. 50.331648 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10668748800 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (8388608 contiguous values) -> 15205 us (6.620313 GB/s assuming good implementation, i.e. 100.663296 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10651971584 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (16777216 contiguous values) -> 30212 us (6.663749 GB/s assuming good implementation, i.e. 201.326592 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10618417152 / 12079136768
