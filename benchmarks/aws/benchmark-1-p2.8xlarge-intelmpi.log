+ which mpicc
/opt/intel/compilers_and_libraries_2017.0.098/linux/mpi/intel64/bin/mpicc
+ which mpirun
/opt/intel/compilers_and_libraries_2017.0.098/linux/mpi/intel64/bin/mpirun
+ nvidia-smi -q -i 0 -d CLOCK

==============NVSMI LOG==============

Timestamp                           : Thu Nov  3 22:46:28 2016
Driver Version                      : 352.99

Attached GPUs                       : 8
GPU 0000:00:17.0
    Clocks
        Graphics                    : 324 MHz
        SM                          : 324 MHz
        Memory                      : 324 MHz
    Applications Clocks
        Graphics                    : 875 MHz
        Memory                      : 2505 MHz
    Default Applications Clocks
        Graphics                    : 562 MHz
        Memory                      : 2505 MHz
    Max Clocks
        Graphics                    : 875 MHz
        SM                          : 875 MHz
        Memory                      : 2505 MHz
    SM Clock Samples
        Duration                    : 28615.72 sec
        Number of Samples           : 100
        Max                         : 875 MHz
        Min                         : 324 MHz
        Avg                         : 867 MHz
    Memory Clock Samples
        Duration                    : 28615.72 sec
        Number of Samples           : 100
        Max                         : 2505 MHz
        Min                         : 324 MHz
        Avg                         : 2500 MHz
    Clock Policy
        Auto Boost                  : On
        Auto Boost Default          : On

+ nvidia-smi topo --matrix
	[4mGPU0	GPU1	GPU2	GPU3	GPU4	GPU5	GPU6	GPU7	CPU Affinity[0m
GPU0	 X 	PHB	PHB	PHB	PHB	PHB	PHB	PHB	0-31
GPU1	PHB	 X 	PHB	PHB	PHB	PHB	PHB	PHB	0-31
GPU2	PHB	PHB	 X 	PHB	PHB	PHB	PHB	PHB	0-31
GPU3	PHB	PHB	PHB	 X 	PHB	PHB	PHB	PHB	0-31
GPU4	PHB	PHB	PHB	PHB	 X 	PHB	PHB	PHB	0-31
GPU5	PHB	PHB	PHB	PHB	PHB	 X 	PHB	PHB	0-31
GPU6	PHB	PHB	PHB	PHB	PHB	PHB	 X 	PHB	0-31
GPU7	PHB	PHB	PHB	PHB	PHB	PHB	PHB	 X 	0-31

Legend:

  X   = Self
  SOC = Path traverses a socket-level link (e.g. QPI)
  PHB = Path traverses a PCIe host bridge
  PXB = Path traverses multiple PCIe internal switches
  PIX = Path traverses a PCIe internal switch
++ echo '2 4 8'
++ tr ' ' '\n'
+ for nproc in '$(echo "2 4 8" | tr " " "\n")'
+ mpirun --bind-to none -n 2 luajit ./test/collectives.lua -all
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (256 contiguous values) -> 3 us (0.292175 GB/s assuming good implementation, i.e. 0.001024 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (512 contiguous values) -> 9 us (0.206986 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (1024 contiguous values) -> 17 us (0.239608 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (2048 contiguous values) -> 5 us (1.576135 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (4096 contiguous values) -> 11 us (1.413981 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (8192 contiguous values) -> 11 us (2.799164 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (16384 contiguous values) -> 20 us (3.196255 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (32768 contiguous values) -> 38 us (3.440274 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (65536 contiguous values) -> 77 us (3.399850 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (131072 contiguous values) -> 138 us (3.785545 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (262144 contiguous values) -> 255 us (4.099214 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (524288 contiguous values) -> 506 us (4.143823 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (1048576 contiguous values) -> 1030 us (4.068592 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (2097152 contiguous values) -> 2064 us (4.062485 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (4194304 contiguous values) -> 7916 us (2.119170 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (8388608 contiguous values) -> 27983 us (1.199062 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.FloatTensor (16777216 contiguous values) -> 56670 us (1.184196 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (256 contiguous values) -> 14 us (0.136565 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (512 contiguous values) -> 8 us (0.505290 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (1024 contiguous values) -> 3 us (2.160990 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (2048 contiguous values) -> 5 us (3.211191 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (4096 contiguous values) -> 7 us (4.674794 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (8192 contiguous values) -> 11 us (5.553089 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (16384 contiguous values) -> 20 us (6.552513 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (32768 contiguous values) -> 40 us (6.490624 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (65536 contiguous values) -> 63 us (8.193082 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (131072 contiguous values) -> 119 us (8.759304 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (262144 contiguous values) -> 220 us (9.493894 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (524288 contiguous values) -> 432 us (9.688928 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (1048576 contiguous values) -> 859 us (9.754199 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (2097152 contiguous values) -> 1715 us (9.782132 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (4194304 contiguous values) -> 5169 us (6.491342 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (8388608 contiguous values) -> 17230 us (3.894818 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.FloatTensor (16777216 contiguous values) -> 34989 us (3.835964 GB/s assuming good implementation, i.e. 134.217728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (256 contiguous values) -> 9 us (0.107643 GB/s assuming good implementation, i.e. 0.001024 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (512 contiguous values) -> 2 us (0.885560 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (1024 contiguous values) -> 3 us (1.235962 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (2048 contiguous values) -> 3 us (2.147484 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (4096 contiguous values) -> 5 us (2.875292 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (8192 contiguous values) -> 8 us (3.765451 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (16384 contiguous values) -> 9 us (7.271902 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (32768 contiguous values) -> 15 us (8.291943 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (65536 contiguous values) -> 31 us (8.242216 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (131072 contiguous values) -> 59 us (8.768035 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (262144 contiguous values) -> 109 us (9.550590 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (524288 contiguous values) -> 214 us (9.790843 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (1048576 contiguous values) -> 423 us (9.913325 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (2097152 contiguous values) -> 855 us (9.799842 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (4194304 contiguous values) -> 1912 us (8.770549 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (8388608 contiguous values) -> 8290 us (4.047530 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.FloatTensor (16777216 contiguous values) -> 17901 us (3.748721 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (256 contiguous values) -> 2 us (0.367091 GB/s assuming good implementation, i.e. 0.001024 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686092800 / 11684478976 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (512 contiguous values) -> 3 us (0.641040 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11684478976 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (1024 contiguous values) -> 3 us (1.108379 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685535744 / 11684478976 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (2048 contiguous values) -> 4 us (1.827646 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11684478976 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (4096 contiguous values) -> 7 us (2.306023 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685535744 / 11684478976 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (8192 contiguous values) -> 11 us (2.899556 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11684478976 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (16384 contiguous values) -> 17 us (3.665039 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685535744 / 11684478976 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (32768 contiguous values) -> 33 us (3.866075 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685535744 / 11684478976 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (65536 contiguous values) -> 66 us (3.947977 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11684478976 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (131072 contiguous values) -> 126 us (4.160877 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11684478976 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (262144 contiguous values) -> 252 us (4.152626 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685535744 / 11684478976 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (524288 contiguous values) -> 500 us (4.188616 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11682381824 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (1048576 contiguous values) -> 1097 us (3.820319 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11682390016 / 11678187520 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (2097152 contiguous values) -> 2307 us (3.635838 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11678195712 / 11669798912 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (4194304 contiguous values) -> 9020 us (1.859944 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11653021696 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (8388608 contiguous values) -> 28941 us (1.159385 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11619467264 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.FloatTensor (16777216 contiguous values) -> 58144 us (1.154170 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11619475456 / 11552358400 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (256 contiguous values) -> 2 us (0.727961 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685535744 / 11684478976 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (512 contiguous values) -> 3 us (1.244918 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11684478976 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (1024 contiguous values) -> 3 us (2.216757 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11684478976 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (2048 contiguous values) -> 4 us (3.335897 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685535744 / 11684478976 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (4096 contiguous values) -> 12 us (2.705491 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11684478976 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (8192 contiguous values) -> 12 us (5.337435 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685535744 / 11684478976 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (16384 contiguous values) -> 19 us (6.688027 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685535744 / 11684478976 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (32768 contiguous values) -> 36 us (7.262296 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685535744 / 11684478976 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (65536 contiguous values) -> 66 us (7.825706 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11684478976 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (131072 contiguous values) -> 122 us (8.568179 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685535744 / 11684478976 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (262144 contiguous values) -> 240 us (8.719363 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11684478976 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (524288 contiguous values) -> 467 us (8.973774 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11682381824 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (1048576 contiguous values) -> 928 us (9.032751 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11678187520 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (2097152 contiguous values) -> 1830 us (9.166416 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11678195712 / 11669798912 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (4194304 contiguous values) -> 4959 us (6.765672 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11669807104 / 11653021696 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (8388608 contiguous values) -> 18015 us (3.725042 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11653029888 / 11619467264 / 12079136768
allreduce (2 processes) (UVA: true) torch.FloatTensor (16777216 contiguous values) -> 36323 us (3.695107 GB/s assuming good implementation, i.e. 134.217728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11619475456 / 11552358400 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (256 contiguous values) -> 2 us (0.466844 GB/s assuming good implementation, i.e. 0.001024 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685535744 / 11684478976 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (512 contiguous values) -> 2 us (0.885560 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685535744 / 11684478976 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (1024 contiguous values) -> 3 us (1.244918 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685535744 / 11684478976 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (2048 contiguous values) -> 3 us (2.057469 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685535744 / 11684478976 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (4096 contiguous values) -> 5 us (2.875292 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685535744 / 11684487168 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (8192 contiguous values) -> 8 us (3.775795 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685535744 / 11684487168 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (16384 contiguous values) -> 9 us (7.048151 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685535744 / 11684478976 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (32768 contiguous values) -> 16 us (7.853654 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11685535744 / 11684478976 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (65536 contiguous values) -> 32 us (7.990637 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11684478976 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (131072 contiguous values) -> 59 us (8.740156 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11684478976 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (262144 contiguous values) -> 114 us (9.197086 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11684478976 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (524288 contiguous values) -> 225 us (9.304097 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11682381824 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (1048576 contiguous values) -> 449 us (9.337183 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686592512 / 11678187520 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (2097152 contiguous values) -> 899 us (9.328766 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11678195712 / 11669798912 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (4194304 contiguous values) -> 1833 us (9.151872 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11669807104 / 11653021696 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (8388608 contiguous values) -> 8395 us (3.996714 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11653029888 / 11619467264 / 12079136768
broadcast (2 processes) (UVA: true) torch.FloatTensor (16777216 contiguous values) -> 18278 us (3.671402 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11619475456 / 11552358400 / 12079136768
+ mpirun --bind-to none -n 2 luajit ./test/collectives.lua -all -gpu
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (256 contiguous values) -> 23 us (0.043384 GB/s assuming good implementation, i.e. 0.001024 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (512 contiguous values) -> 30 us (0.066076 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (1024 contiguous values) -> 26 us (0.155193 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (2048 contiguous values) -> 27 us (0.295695 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (4096 contiguous values) -> 38 us (0.427892 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (8192 contiguous values) -> 33 us (0.967199 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (16384 contiguous values) -> 52 us (1.255724 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (32768 contiguous values) -> 75 us (1.743043 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (65536 contiguous values) -> 126 us (2.072204 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (131072 contiguous values) -> 232 us (2.259812 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (262144 contiguous values) -> 428 us (2.449892 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (524288 contiguous values) -> 843 us (2.485966 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11685044224 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (1048576 contiguous values) -> 1752 us (2.393299 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11682947072 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (2097152 contiguous values) -> 4141 us (2.025688 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11678752768 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (4194304 contiguous values) -> 11267 us (1.489046 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11670364160 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (8388608 contiguous values) -> 33850 us (0.991265 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11653586944 / 12079136768
sendreceivenext (2 processes) (UVA: nil) torch.CudaTensor (16777216 contiguous values) -> 68692 us (0.976947 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11620032512 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (256 contiguous values) -> 31 us (0.064635 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (512 contiguous values) -> 22 us (0.182959 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (1024 contiguous values) -> 19 us (0.411494 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (2048 contiguous values) -> 22 us (0.734968 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (4096 contiguous values) -> 30 us (1.084759 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (8192 contiguous values) -> 34 us (1.877581 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (16384 contiguous values) -> 47 us (2.741924 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (32768 contiguous values) -> 75 us (3.494951 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (65536 contiguous values) -> 123 us (4.248499 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (131072 contiguous values) -> 217 us (4.825065 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (262144 contiguous values) -> 404 us (5.190967 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (524288 contiguous values) -> 776 us (5.400849 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11685044224 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (1048576 contiguous values) -> 1526 us (5.493524 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11682947072 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (2097152 contiguous values) -> 3074 us (5.457057 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11678752768 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (4194304 contiguous values) -> 7660 us (4.379952 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11670364160 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (8388608 contiguous values) -> 22921 us (2.927767 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11653586944 / 12079136768
allreduce (2 processes) (UVA: nil) torch.CudaTensor (16777216 contiguous values) -> 46603 us (2.880011 GB/s assuming good implementation, i.e. 134.217728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11620032512 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (256 contiguous values) -> 27 us (0.037511 GB/s assuming good implementation, i.e. 0.001024 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (512 contiguous values) -> 23 us (0.089015 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (1024 contiguous values) -> 19 us (0.214480 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (2048 contiguous values) -> 20 us (0.397682 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (4096 contiguous values) -> 24 us (0.663315 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (8192 contiguous values) -> 29 us (1.121951 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (16384 contiguous values) -> 37 us (1.753048 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11687141376 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (32768 contiguous values) -> 54 us (2.392323 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (65536 contiguous values) -> 90 us (2.903384 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (131072 contiguous values) -> 156 us (3.358313 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (262144 contiguous values) -> 288 us (3.632048 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11686092800 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (524288 contiguous values) -> 555 us (3.775309 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11685044224 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (1048576 contiguous values) -> 1092 us (3.840250 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11682947072 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (2097152 contiguous values) -> 2174 us (3.858443 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11678752768 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (4194304 contiguous values) -> 4501 us (3.727355 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11670364160 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (8388608 contiguous values) -> 13483 us (2.488515 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11653586944 / 12079136768
broadcast (2 processes) (UVA: nil) torch.CudaTensor (16777216 contiguous values) -> 28959 us (2.317328 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11620032512 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (256 contiguous values) -> 26 us (0.038042 GB/s assuming good implementation, i.e. 0.001024 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11687141376 / 11685801984 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (512 contiguous values) -> 10 us (0.186333 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (1024 contiguous values) -> 15 us (0.261092 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (2048 contiguous values) -> 12 us (0.649522 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (4096 contiguous values) -> 18 us (0.879891 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (8192 contiguous values) -> 19 us (1.680183 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (16384 contiguous values) -> 32 us (2.042184 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (32768 contiguous values) -> 43 us (2.999213 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (65536 contiguous values) -> 76 us (3.408282 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (131072 contiguous values) -> 133 us (3.921225 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (262144 contiguous values) -> 248 us (4.224829 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (524288 contiguous values) -> 494 us (4.241738 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11684753408 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (1048576 contiguous values) -> 1058 us (3.961758 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11682656256 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (2097152 contiguous values) -> 2559 us (3.277843 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11678461952 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (4194304 contiguous values) -> 8476 us (1.979146 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11670073344 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (8388608 contiguous values) -> 28653 us (1.171046 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11653296128 / 12079136768
sendreceivenext (2 processes) (UVA: true) torch.CudaTensor (16777216 contiguous values) -> 57104 us (1.175185 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11619741696 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (256 contiguous values) -> 27 us (0.075549 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (512 contiguous values) -> 10 us (0.379247 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (1024 contiguous values) -> 11 us (0.711382 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (2048 contiguous values) -> 12 us (1.270231 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (4096 contiguous values) -> 20 us (1.598127 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (8192 contiguous values) -> 20 us (3.196255 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (16384 contiguous values) -> 27 us (4.682758 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (32768 contiguous values) -> 46 us (5.676364 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (65536 contiguous values) -> 73 us (7.135053 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (131072 contiguous values) -> 128 us (8.191556 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (262144 contiguous values) -> 231 us (9.058798 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (524288 contiguous values) -> 446 us (9.400046 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11684753408 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (1048576 contiguous values) -> 884 us (9.489285 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11682656256 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (2097152 contiguous values) -> 1757 us (9.548775 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11678461952 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (4194304 contiguous values) -> 4808 us (6.977565 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11670073344 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (8388608 contiguous values) -> 17690 us (3.793474 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11653296128 / 12079136768
allreduce (2 processes) (UVA: true) torch.CudaTensor (16777216 contiguous values) -> 35624 us (3.767621 GB/s assuming good implementation, i.e. 134.217728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11619741696 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (256 contiguous values) -> 17 us (0.058916 GB/s assuming good implementation, i.e. 0.001024 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (512 contiguous values) -> 8 us (0.240614 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (1024 contiguous values) -> 9 us (0.413973 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685810176 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (2048 contiguous values) -> 10 us (0.786264 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686858752 / 11685810176 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (4096 contiguous values) -> 12 us (1.270231 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686858752 / 11685810176 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (8192 contiguous values) -> 16 us (1.963414 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686858752 / 11685810176 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (16384 contiguous values) -> 17 us (3.791419 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686858752 / 11685801984 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (32768 contiguous values) -> 24 us (5.286114 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (65536 contiguous values) -> 39 us (6.572096 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (131072 contiguous values) -> 68 us (7.678154 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (262144 contiguous values) -> 118 us (8.849188 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11685801984 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (524288 contiguous values) -> 222 us (9.438881 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11684753408 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (1048576 contiguous values) -> 429 us (9.768010 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11682656256 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (2097152 contiguous values) -> 844 us (9.935440 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11678461952 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (4194304 contiguous values) -> 1734 us (9.673211 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11670073344 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (8388608 contiguous values) -> 7942 us (4.224613 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11653296128 / 12079136768
broadcast (2 processes) (UVA: true) torch.CudaTensor (16777216 contiguous values) -> 17640 us (3.804225 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11686866944 / 11619741696 / 12079136768
+ for nproc in '$(echo "2 4 8" | tr " " "\n")'
+ mpirun --bind-to none -n 4 luajit ./test/collectives.lua -all
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (256 contiguous values) -> 11 us (0.089107 GB/s assuming good implementation, i.e. 0.001024 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (512 contiguous values) -> 5 us (0.371859 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (1024 contiguous values) -> 9 us (0.454494 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (2048 contiguous values) -> 13 us (0.616871 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (4096 contiguous values) -> 21 us (0.776491 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (8192 contiguous values) -> 14 us (2.202547 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (16384 contiguous values) -> 31 us (2.093510 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (32768 contiguous values) -> 37 us (3.457584 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (65536 contiguous values) -> 72 us (3.616815 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (131072 contiguous values) -> 199 us (2.626640 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (262144 contiguous values) -> 261 us (4.006602 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (524288 contiguous values) -> 518 us (4.045483 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (1048576 contiguous values) -> 1036 us (4.045390 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (2097152 contiguous values) -> 4334 us (1.935270 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (4194304 contiguous values) -> 9214 us (1.820760 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (8388608 contiguous values) -> 29656 us (1.131432 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.FloatTensor (16777216 contiguous values) -> 58940 us (1.138592 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (256 contiguous values) -> 21 us (0.095763 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (512 contiguous values) -> 9 us (0.426299 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (1024 contiguous values) -> 5 us (1.487435 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (2048 contiguous values) -> 8 us (2.003483 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (4096 contiguous values) -> 11 us (2.924233 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (8192 contiguous values) -> 19 us (3.448907 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (16384 contiguous values) -> 30 us (4.352778 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (32768 contiguous values) -> 60 us (4.305057 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (65536 contiguous values) -> 106 us (4.922819 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (131072 contiguous values) -> 231 us (4.525670 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (262144 contiguous values) -> 342 us (6.122855 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (524288 contiguous values) -> 836 us (5.015305 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (1048576 contiguous values) -> 1654 us (5.071402 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (2097152 contiguous values) -> 4356 us (3.851432 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (4194304 contiguous values) -> 11929 us (2.812657 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (8388608 contiguous values) -> 29992 us (2.237537 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.FloatTensor (16777216 contiguous values) -> 59254 us (2.265121 GB/s assuming good implementation, i.e. 134.217728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (256 contiguous values) -> 12 us (0.165191 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (512 contiguous values) -> 2 us (1.455921 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (1024 contiguous values) -> 3 us (2.337397 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (2048 contiguous values) -> 3 us (4.321980 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (4096 contiguous values) -> 5 us (5.632744 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (8192 contiguous values) -> 8 us (7.898790 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (16384 contiguous values) -> 24 us (5.437743 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (32768 contiguous values) -> 38 us (6.880548 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (65536 contiguous values) -> 72 us (7.262296 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (131072 contiguous values) -> 137 us (7.598560 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (262144 contiguous values) -> 264 us (7.919414 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (524288 contiguous values) -> 514 us (8.160020 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (1048576 contiguous values) -> 1020 us (8.221800 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (2097152 contiguous values) -> 2070 us (8.101398 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (4194304 contiguous values) -> 7915 us (4.239081 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (8388608 contiguous values) -> 17811 us (3.767724 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.FloatTensor (16777216 contiguous values) -> 35509 us (3.779760 GB/s assuming good implementation, i.e. 134.217728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (256 contiguous values) -> 3 us (0.318146 GB/s assuming good implementation, i.e. 0.001024 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11351277568 / 11348058112 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (512 contiguous values) -> 4 us (0.499415 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11351228416 / 11348058112 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (1024 contiguous values) -> 3 us (1.080495 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11350179840 / 11348058112 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (2048 contiguous values) -> 6 us (1.363482 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11351228416 / 11348058112 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (4096 contiguous values) -> 10 us (1.561806 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11350179840 / 11348058112 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (8192 contiguous values) -> 12 us (2.684355 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11350179840 / 11348058112 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (16384 contiguous values) -> 18 us (3.542241 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11351228416 / 11348058112 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (32768 contiguous values) -> 35 us (3.712058 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11351228416 / 11348058112 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (65536 contiguous values) -> 67 us (3.860645 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11351228416 / 11348058112 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (131072 contiguous values) -> 191 us (2.740557 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11351228416 / 11348058112 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (262144 contiguous values) -> 364 us (2.875104 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11350179840 / 11348058112 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (524288 contiguous values) -> 512 us (4.095206 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11350179840 / 11343863808 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (1048576 contiguous values) -> 1141 us (3.673380 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11343888384 / 11335475200 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (2097152 contiguous values) -> 4697 us (1.785646 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11335499776 / 11318697984 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (4194304 contiguous values) -> 10159 us (1.651414 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11335499776 / 11285143552 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (8388608 contiguous values) -> 30374 us (1.104679 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11285168128 / 11218034688 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.FloatTensor (16777216 contiguous values) -> 60918 us (1.101608 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11150950400 / 11083816960 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (256 contiguous values) -> 9 us (0.224867 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11349114880 / 11348058112 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (512 contiguous values) -> 8 us (0.470681 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11351228416 / 11348058112 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (1024 contiguous values) -> 9 us (0.899470 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11351228416 / 11348058112 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (2048 contiguous values) -> 7 us (2.076117 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11351228416 / 11348058112 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (4096 contiguous values) -> 21 us (1.560034 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11351228416 / 11348058112 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (8192 contiguous values) -> 17 us (3.660159 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11351228416 / 11348058112 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (16384 contiguous values) -> 30 us (4.339036 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11351228416 / 11348058112 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (32768 contiguous values) -> 59 us (4.375295 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11350179840 / 11348058112 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (65536 contiguous values) -> 103 us (5.075059 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11350179840 / 11348058112 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (131072 contiguous values) -> 193 us (5.410317 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11351228416 / 11348058112 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (262144 contiguous values) -> 443 us (4.732899 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11351228416 / 11348058112 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (524288 contiguous values) -> 918 us (4.568450 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11348082688 / 11343863808 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (1048576 contiguous values) -> 1797 us (4.666053 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11348082688 / 11335475200 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (2097152 contiguous values) -> 4608 us (3.640108 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11335499776 / 11318697984 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (4194304 contiguous values) -> 12085 us (2.776490 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11335499776 / 11285143552 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (8388608 contiguous values) -> 31165 us (2.153280 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11285168128 / 11218034688 / 12079136768
allreduce (4 processes) (UVA: true) torch.FloatTensor (16777216 contiguous values) -> 63661 us (2.108290 GB/s assuming good implementation, i.e. 134.217728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11218042880 / 11083816960 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (256 contiguous values) -> 2 us (1.022611 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11350171648 / 11348058112 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (512 contiguous values) -> 2 us (1.700977 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11349114880 / 11348066304 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (1024 contiguous values) -> 3 us (2.402779 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11349114880 / 11348066304 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (2048 contiguous values) -> 3 us (4.839400 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11349114880 / 11348074496 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (4096 contiguous values) -> 4 us (7.635497 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11349114880 / 11348058112 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (8192 contiguous values) -> 8 us (7.614346 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11349114880 / 11348066304 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (16384 contiguous values) -> 22 us (5.750584 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11349114880 / 11348058112 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (32768 contiguous values) -> 41 us (6.348220 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11351228416 / 11348058112 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (65536 contiguous values) -> 75 us (6.934794 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11350179840 / 11348058112 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (131072 contiguous values) -> 140 us (7.474586 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11351228416 / 11348058112 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (262144 contiguous values) -> 275 us (7.601187 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11351228416 / 11348058112 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (524288 contiguous values) -> 550 us (7.624577 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11350179840 / 11343863808 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (1048576 contiguous values) -> 1090 us (7.689061 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11348082688 / 11335475200 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (2097152 contiguous values) -> 2223 us (7.544385 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11343888384 / 11318697984 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (4194304 contiguous values) -> 8293 us (4.046111 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11335499776 / 11285143552 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (8388608 contiguous values) -> 18248 us (3.677599 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11318722560 / 11218034688 / 12079136768
broadcast (4 processes) (UVA: true) torch.FloatTensor (16777216 contiguous values) -> 36392 us (3.688041 GB/s assuming good implementation, i.e. 134.217728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11218059264 / 11083816960 / 12079136768
+ mpirun --bind-to none -n 4 luajit ./test/collectives.lua -all -gpu
sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (256 contiguous values) -> 19 us (0.053024 GB/s assuming good implementation, i.e. 0.001024 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (512 contiguous values) -> 27 us (0.073670 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (1024 contiguous values) -> 40 us (0.102383 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (2048 contiguous values) -> 24 us (0.335872 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (4096 contiguous values) -> 45 us (0.358474 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (8192 contiguous values) -> 38 us (0.842150 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (16384 contiguous values) -> 64 us (1.019199 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (32768 contiguous values) -> 97 us (1.342833 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (65536 contiguous values) -> 175 us (1.495324 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (131072 contiguous values) -> 321 us (1.628665 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (262144 contiguous values) -> 605 us (1.731174 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (524288 contiguous values) -> 1199 us (1.747788 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11351285760 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (1048576 contiguous values) -> 2516 us (1.666984 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11349188608 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (2097152 contiguous values) -> 7558 us (1.109882 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11344994304 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (4194304 contiguous values) -> 15811 us (1.061063 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11336605696 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (8388608 contiguous values) -> 41147 us (0.815459 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11319828480 / 12079136768
sendreceivenext (4 processes) (UVA: nil) torch.CudaTensor (16777216 contiguous values) -> 82489 us (0.813547 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11286274048 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (256 contiguous values) -> 39 us (0.051591 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (512 contiguous values) -> 31 us (0.130447 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (1024 contiguous values) -> 22 us (0.372262 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (2048 contiguous values) -> 27 us (0.589361 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (4096 contiguous values) -> 32 us (1.001742 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (8192 contiguous values) -> 48 us (1.362130 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (16384 contiguous values) -> 69 us (1.878223 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (32768 contiguous values) -> 119 us (2.184605 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (65536 contiguous values) -> 206 us (2.544871 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (131072 contiguous values) -> 378 us (2.770248 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (262144 contiguous values) -> 701 us (2.988615 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (524288 contiguous values) -> 1403 us (2.988869 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11351285760 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (1048576 contiguous values) -> 2659 us (3.154672 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11349188608 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (2097152 contiguous values) -> 6283 us (2.669963 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11344994304 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (4194304 contiguous values) -> 16410 us (2.044655 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11336605696 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (8388608 contiguous values) -> 37465 us (1.791213 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11319828480 / 12079136768
allreduce (4 processes) (UVA: nil) torch.CudaTensor (16777216 contiguous values) -> 76829 us (1.746945 GB/s assuming good implementation, i.e. 134.217728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11286274048 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (256 contiguous values) -> 29 us (0.070352 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (512 contiguous values) -> 24 us (0.165829 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (1024 contiguous values) -> 19 us (0.424194 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (2048 contiguous values) -> 20 us (0.784469 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (4096 contiguous values) -> 25 us (1.305213 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (8192 contiguous values) -> 30 us (2.127538 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (16384 contiguous values) -> 61 us (2.131663 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11353382912 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (32768 contiguous values) -> 99 us (2.623507 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (65536 contiguous values) -> 173 us (3.026873 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (131072 contiguous values) -> 321 us (3.264583 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (262144 contiguous values) -> 612 us (3.421672 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352334336 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (524288 contiguous values) -> 1179 us (3.555414 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11351285760 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (1048576 contiguous values) -> 2311 us (3.628901 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11349188608 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (2097152 contiguous values) -> 4604 us (3.643897 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11344994304 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (4194304 contiguous values) -> 13542 us (2.477677 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11336605696 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (8388608 contiguous values) -> 29134 us (2.303407 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11319828480 / 12079136768
broadcast (4 processes) (UVA: nil) torch.CudaTensor (16777216 contiguous values) -> 58490 us (2.294697 GB/s assuming good implementation, i.e. 134.217728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11286274048 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (256 contiguous values) -> 32 us (0.031146 GB/s assuming good implementation, i.e. 0.001024 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353382912 / 11352027136 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (512 contiguous values) -> 16 us (0.122713 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (1024 contiguous values) -> 11 us (0.353495 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (2048 contiguous values) -> 19 us (0.428961 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (4096 contiguous values) -> 19 us (0.827946 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (8192 contiguous values) -> 21 us (1.537348 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (16384 contiguous values) -> 37 us (1.747476 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (32768 contiguous values) -> 50 us (2.616639 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (65536 contiguous values) -> 81 us (3.224374 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (131072 contiguous values) -> 146 us (3.576229 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (262144 contiguous values) -> 377 us (2.774618 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (524288 contiguous values) -> 752 us (2.786131 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11350978560 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (1048576 contiguous values) -> 1198 us (3.499331 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11348881408 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (2097152 contiguous values) -> 6506 us (1.289287 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11344687104 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (4194304 contiguous values) -> 10233 us (1.639475 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11336298496 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (8388608 contiguous values) -> 30630 us (1.095444 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11319521280 / 12079136768
sendreceivenext (4 processes) (UVA: true) torch.CudaTensor (16777216 contiguous values) -> 60892 us (1.102095 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11285966848 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (256 contiguous values) -> 27 us (0.075284 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (512 contiguous values) -> 12 us (0.332943 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (1024 contiguous values) -> 13 us (0.602802 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (2048 contiguous values) -> 16 us (0.974744 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (4096 contiguous values) -> 24 us (1.321528 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (8192 contiguous values) -> 26 us (2.480848 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (16384 contiguous values) -> 40 us (3.213067 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (32768 contiguous values) -> 67 us (3.883828 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (65536 contiguous values) -> 114 us (4.587032 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (131072 contiguous values) -> 232 us (4.515448 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (262144 contiguous values) -> 443 us (4.726541 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (524288 contiguous values) -> 890 us (4.709460 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11350978560 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (1048576 contiguous values) -> 1719 us (4.877979 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11348881408 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (2097152 contiguous values) -> 4535 us (3.699335 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11344687104 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (4194304 contiguous values) -> 12110 us (2.770783 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11336298496 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (8388608 contiguous values) -> 31388 us (2.137981 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11319521280 / 12079136768
allreduce (4 processes) (UVA: true) torch.CudaTensor (16777216 contiguous values) -> 64010 us (2.096824 GB/s assuming good implementation, i.e. 134.217728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11285966848 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (256 contiguous values) -> 13 us (0.149390 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (512 contiguous values) -> 8 us (0.465579 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (1024 contiguous values) -> 10 us (0.765250 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (2048 contiguous values) -> 9 us (1.688439 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (4096 contiguous values) -> 12 us (2.643057 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (8192 contiguous values) -> 14 us (4.521018 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352035328 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (16384 contiguous values) -> 32 us (3.983738 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (32768 contiguous values) -> 51 us (5.099776 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (65536 contiguous values) -> 85 us (6.110095 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (131072 contiguous values) -> 156 us (6.716626 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (262144 contiguous values) -> 293 us (7.140845 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11352027136 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (524288 contiguous values) -> 564 us (7.435413 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11350978560 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (1048576 contiguous values) -> 1098 us (7.639310 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11348881408 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (2097152 contiguous values) -> 2170 us (7.731130 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11344687104 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (4194304 contiguous values) -> 7938 us (4.226579 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11336298496 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (8388608 contiguous values) -> 17963 us (3.735904 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11319521280 / 12079136768
broadcast (4 processes) (UVA: true) torch.CudaTensor (16777216 contiguous values) -> 35780 us (3.751132 GB/s assuming good implementation, i.e. 134.217728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 11353108480 / 11285966848 / 12079136768
+ for nproc in '$(echo "2 4 8" | tr " " "\n")'
+ mpirun --bind-to none -n 8 luajit ./test/collectives.lua -all
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (256 contiguous values) -> 376 us (0.002722 GB/s assuming good implementation, i.e. 0.001024 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (512 contiguous values) -> 8 us (0.227850 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (1024 contiguous values) -> 11 us (0.343597 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (2048 contiguous values) -> 16 us (0.481904 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (4096 contiguous values) -> 36 us (0.450029 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (8192 contiguous values) -> 14 us (2.199023 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (16384 contiguous values) -> 27 us (2.349384 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (32768 contiguous values) -> 41 us (3.127166 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (65536 contiguous values) -> 76 us (3.408282 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (131072 contiguous values) -> 171 us (3.055472 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (262144 contiguous values) -> 267 us (3.921225 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (524288 contiguous values) -> 534 us (3.923499 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (1048576 contiguous values) -> 3070 us (1.365864 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (2097152 contiguous values) -> 6753 us (1.242149 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (4194304 contiguous values) -> 13092 us (1.281389 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (8388608 contiguous values) -> 35859 us (0.935727 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.FloatTensor (16777216 contiguous values) -> 71411 us (0.939753 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (256 contiguous values) -> 19 us (0.102873 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (512 contiguous values) -> 10 us (0.372665 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (1024 contiguous values) -> 7 us (1.077108 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (2048 contiguous values) -> 14 us (1.099512 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (4096 contiguous values) -> 16 us (2.009341 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (8192 contiguous values) -> 23 us (2.787808 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (16384 contiguous values) -> 49 us (2.646874 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (32768 contiguous values) -> 73 us (3.576811 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (65536 contiguous values) -> 137 us (3.826385 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (131072 contiguous values) -> 241 us (4.343750 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (262144 contiguous values) -> 521 us (4.024567 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (524288 contiguous values) -> 969 us (4.327082 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (1048576 contiguous values) -> 2641 us (3.175342 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (2097152 contiguous values) -> 7727 us (2.171245 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (4194304 contiguous values) -> 18547 us (1.809088 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (8388608 contiguous values) -> 42203 us (1.590107 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.FloatTensor (16777216 contiguous values) -> 84458 us (1.589156 GB/s assuming good implementation, i.e. 134.217728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (256 contiguous values) -> 14 us (0.208831 GB/s assuming good implementation, i.e. 0.003072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (512 contiguous values) -> 8 us (0.707962 GB/s assuming good implementation, i.e. 0.006144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (1024 contiguous values) -> 4 us (2.726963 GB/s assuming good implementation, i.e. 0.012288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (2048 contiguous values) -> 4 us (5.102931 GB/s assuming good implementation, i.e. 0.024576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (4096 contiguous values) -> 5 us (8.346495 GB/s assuming good implementation, i.e. 0.049152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (8192 contiguous values) -> 20 us (4.816786 GB/s assuming good implementation, i.e. 0.098304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (16384 contiguous values) -> 38 us (5.118769 GB/s assuming good implementation, i.e. 0.196608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (32768 contiguous values) -> 70 us (5.577502 GB/s assuming good implementation, i.e. 0.393216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (65536 contiguous values) -> 69 us (11.280899 GB/s assuming good implementation, i.e. 0.786432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (131072 contiguous values) -> 118 us (13.273782 GB/s assuming good implementation, i.e. 1.572864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (262144 contiguous values) -> 230 us (13.658530 GB/s assuming good implementation, i.e. 3.145728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (524288 contiguous values) -> 461 us (13.647227 GB/s assuming good implementation, i.e. 6.291456 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (1048576 contiguous values) -> 7048 us (1.785193 GB/s assuming good implementation, i.e. 12.582912 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (2097152 contiguous values) -> 4201 us (5.989713 GB/s assuming good implementation, i.e. 25.165824 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (4194304 contiguous values) -> 9840 us (5.114999 GB/s assuming good implementation, i.e. 50.331648 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (8388608 contiguous values) -> 17386 us (5.789839 GB/s assuming good implementation, i.e. 100.663296 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.FloatTensor (16777216 contiguous values) -> 34850 us (5.776784 GB/s assuming good implementation, i.e. 201.326592 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684534784 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (256 contiguous values) -> 3 us (0.284435 GB/s assuming good implementation, i.e. 0.001024 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10683478016 / 10675216384 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (512 contiguous values) -> 4 us (0.445074 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10681565184 / 10675216384 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (1024 contiguous values) -> 87 us (0.046812 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10682613760 / 10675216384 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (2048 contiguous values) -> 5 us (1.487435 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10682613760 / 10675216384 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (4096 contiguous values) -> 9 us (1.640083 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10682613760 / 10675216384 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (8192 contiguous values) -> 15 us (2.114445 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10681565184 / 10675216384 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (16384 contiguous values) -> 18 us (3.524076 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10682613760 / 10675216384 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (32768 contiguous values) -> 37 us (3.512817 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10682613760 / 10675216384 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (65536 contiguous values) -> 72 us (3.604956 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10682613760 / 10675216384 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (131072 contiguous values) -> 151 us (3.451614 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10681565184 / 10675216384 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (262144 contiguous values) -> 256 us (4.092729 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10682613760 / 10675216384 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (524288 contiguous values) -> 653 us (3.207210 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10681565184 / 10666827776 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (1048576 contiguous values) -> 2750 us (1.524929 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10671079424 / 10650050560 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (2097152 contiguous values) -> 6486 us (1.293239 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10675273728 / 10616496128 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (4194304 contiguous values) -> 13024 us (1.288118 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10650107904 / 10549387264 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (8388608 contiguous values) -> 35776 us (0.937888 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10515881984 / 10415169536 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.FloatTensor (16777216 contiguous values) -> 71294 us (0.941286 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10549436416 / 10146734080 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (256 contiguous values) -> 5 us (0.385199 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10681556992 / 10675216384 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (512 contiguous values) -> 11 us (0.355691 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10680516608 / 10675216384 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (1024 contiguous values) -> 7 us (1.050757 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10681565184 / 10675216384 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (2048 contiguous values) -> 19 us (0.836003 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10682613760 / 10675216384 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (4096 contiguous values) -> 15 us (2.114445 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10682613760 / 10675216384 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (8192 contiguous values) -> 28 us (2.283039 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10682613760 / 10675216384 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (16384 contiguous values) -> 41 us (3.127166 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10682613760 / 10675216384 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (32768 contiguous values) -> 71 us (3.651649 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10682613760 / 10675216384 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (65536 contiguous values) -> 129 us (4.033425 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10682613760 / 10675216384 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (131072 contiguous values) -> 267 us (3.912853 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10681565184 / 10675216384 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (262144 contiguous values) -> 559 us (3.750200 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10682613760 / 10675216384 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (524288 contiguous values) -> 1092 us (3.839161 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10681565184 / 10666827776 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (1048576 contiguous values) -> 2739 us (3.062093 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10675273728 / 10650050560 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (2097152 contiguous values) -> 7960 us (2.107688 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10666876928 / 10616496128 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (4194304 contiguous values) -> 19353 us (1.733758 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10650099712 / 10549387264 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (8388608 contiguous values) -> 42676 us (1.572509 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10582999040 / 10415169536 / 12079136768
allreduce (8 processes) (UVA: true) torch.FloatTensor (16777216 contiguous values) -> 85361 us (1.572343 GB/s assuming good implementation, i.e. 134.217728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10482327552 / 10146734080 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (256 contiguous values) -> 3 us (0.831284 GB/s assuming good implementation, i.e. 0.003072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10480214016 / 10675216384 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (512 contiguous values) -> 2 us (2.684355 GB/s assuming good implementation, i.e. 0.006144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10679459840 / 10675216384 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (1024 contiguous values) -> 2 us (4.685419 GB/s assuming good implementation, i.e. 0.012288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10678403072 / 10675216384 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (2048 contiguous values) -> 2 us (8.449116 GB/s assuming good implementation, i.e. 0.024576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10678403072 / 10675216384 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (4096 contiguous values) -> 3 us (12.570636 GB/s assuming good implementation, i.e. 0.049152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10678403072 / 10675216384 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (8192 contiguous values) -> 11 us (8.466465 GB/s assuming good implementation, i.e. 0.098304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10678403072 / 10675216384 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (16384 contiguous values) -> 20 us (9.456809 GB/s assuming good implementation, i.e. 0.196608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10676314112 / 10675216384 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (32768 contiguous values) -> 38 us (10.263021 GB/s assuming good implementation, i.e. 0.393216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10679451648 / 10675216384 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (65536 contiguous values) -> 66 us (11.793117 GB/s assuming good implementation, i.e. 0.786432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10677362688 / 10675216384 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (131072 contiguous values) -> 121 us (12.965939 GB/s assuming good implementation, i.e. 1.572864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10679451648 / 10675216384 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (262144 contiguous values) -> 228 us (13.789862 GB/s assuming good implementation, i.e. 3.145728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10679443456 / 10675216384 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (524288 contiguous values) -> 455 us (13.808623 GB/s assuming good implementation, i.e. 6.291456 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10677338112 / 10666827776 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (1048576 contiguous values) -> 898 us (14.004288 GB/s assuming good implementation, i.e. 12.582912 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10668941312 / 10650050560 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (2097152 contiguous values) -> 3159 us (7.964890 GB/s assuming good implementation, i.e. 25.165824 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10658455552 / 10608107520 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (4194304 contiguous values) -> 8681 us (5.797503 GB/s assuming good implementation, i.e. 50.331648 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10616504320 / 10532610048 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (8388608 contiguous values) -> 23765 us (4.235777 GB/s assuming good implementation, i.e. 100.663296 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10549436416 / 10381615104 / 12079136768
broadcast (8 processes) (UVA: true) torch.FloatTensor (16777216 contiguous values) -> 34034 us (5.915283 GB/s assuming good implementation, i.e. 201.326592 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10348101632 / 10213851136 / 12079136768
+ mpirun --bind-to none -n 8 luajit ./test/collectives.lua -all -gpu
sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (256 contiguous values) -> 180 us (0.005663 GB/s assuming good implementation, i.e. 0.001024 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (512 contiguous values) -> 51 us (0.039549 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (1024 contiguous values) -> 85 us (0.047802 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (2048 contiguous values) -> 33 us (0.243859 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (4096 contiguous values) -> 70 us (0.233422 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (8192 contiguous values) -> 68 us (0.481229 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (16384 contiguous values) -> 73 us (0.888135 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (32768 contiguous values) -> 131 us (0.998285 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (65536 contiguous values) -> 265 us (0.985844 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (131072 contiguous values) -> 444 us (1.178406 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (262144 contiguous values) -> 923 us (1.135185 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (524288 contiguous values) -> 1962 us (1.068615 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10683768832 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (1048576 contiguous values) -> 5690 us (0.737071 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10681671680 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (2097152 contiguous values) -> 10321 us (0.812762 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10677477376 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (4194304 contiguous values) -> 24528 us (0.684000 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10669088768 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (8388608 contiguous values) -> 61000 us (0.550067 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10652311552 / 12079136768
sendreceivenext (8 processes) (UVA: nil) torch.CudaTensor (16777216 contiguous values) -> 116323 us (0.576914 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10618757120 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (256 contiguous values) -> 47 us (0.043405 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (512 contiguous values) -> 43 us (0.095232 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (1024 contiguous values) -> 30 us (0.271404 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (2048 contiguous values) -> 41 us (0.390230 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (4096 contiguous values) -> 43 us (0.749803 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (8192 contiguous values) -> 64 us (1.022231 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (16384 contiguous values) -> 104 us (1.249445 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (32768 contiguous values) -> 175 us (1.492887 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (65536 contiguous values) -> 315 us (1.659765 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (131072 contiguous values) -> 597 us (1.755497 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (262144 contiguous values) -> 1127 us (1.860032 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (524288 contiguous values) -> 2192 us (1.912776 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10683768832 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (1048576 contiguous values) -> 4813 us (1.742793 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10681671680 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (2097152 contiguous values) -> 11716 us (1.431930 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10677477376 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (4194304 contiguous values) -> 28660 us (1.170764 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10669088768 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (8388608 contiguous values) -> 59400 us (1.129771 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10652311552 / 12079136768
allreduce (8 processes) (UVA: nil) torch.CudaTensor (16777216 contiguous values) -> 124798 us (1.075475 GB/s assuming good implementation, i.e. 134.217728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10618757120 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (256 contiguous values) -> 30 us (0.100116 GB/s assuming good implementation, i.e. 0.003072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (512 contiguous values) -> 27 us (0.223502 GB/s assuming good implementation, i.e. 0.006144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (1024 contiguous values) -> 20 us (0.614298 GB/s assuming good implementation, i.e. 0.012288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (2048 contiguous values) -> 22 us (1.102451 GB/s assuming good implementation, i.e. 0.024576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (4096 contiguous values) -> 26 us (1.882725 GB/s assuming good implementation, i.e. 0.049152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (8192 contiguous values) -> 48 us (2.006408 GB/s assuming good implementation, i.e. 0.098304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (16384 contiguous values) -> 79 us (2.488333 GB/s assuming good implementation, i.e. 0.196608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10685865984 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (32768 contiguous values) -> 1710 us (0.229831 GB/s assuming good implementation, i.e. 0.393216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (65536 contiguous values) -> 111 us (7.040629 GB/s assuming good implementation, i.e. 0.786432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (131072 contiguous values) -> 319 us (4.925760 GB/s assuming good implementation, i.e. 1.572864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (262144 contiguous values) -> 342 us (9.176617 GB/s assuming good implementation, i.e. 3.145728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684817408 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (524288 contiguous values) -> 761 us (8.258467 GB/s assuming good implementation, i.e. 6.291456 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10683768832 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (1048576 contiguous values) -> 1740 us (7.229467 GB/s assuming good implementation, i.e. 12.582912 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10681671680 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (2097152 contiguous values) -> 10695 us (2.353045 GB/s assuming good implementation, i.e. 25.165824 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10677477376 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (4194304 contiguous values) -> 19044 us (2.642828 GB/s assuming good implementation, i.e. 50.331648 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10669088768 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (8388608 contiguous values) -> 39393 us (2.555354 GB/s assuming good implementation, i.e. 100.663296 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10652311552 / 12079136768
broadcast (8 processes) (UVA: nil) torch.CudaTensor (16777216 contiguous values) -> 77809 us (2.587446 GB/s assuming good implementation, i.e. 201.326592 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10618757120 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (256 contiguous values) -> 31 us (0.032390 GB/s assuming good implementation, i.e. 0.001024 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685865984 / 10684477440 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (512 contiguous values) -> 13 us (0.151498 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (1024 contiguous values) -> 15 us (0.267599 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (2048 contiguous values) -> 98 us (0.082834 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (4096 contiguous values) -> 101 us (0.160635 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (8192 contiguous values) -> 110 us (0.296780 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (16384 contiguous values) -> 30 us (2.171231 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (32768 contiguous values) -> 54 us (2.427178 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (65536 contiguous values) -> 79 us (3.277233 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (131072 contiguous values) -> 160 us (3.262646 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (262144 contiguous values) -> 274 us (3.826718 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (524288 contiguous values) -> 577 us (3.629051 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10683428864 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (1048576 contiguous values) -> 2801 us (1.497207 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10681331712 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (2097152 contiguous values) -> 6894 us (1.216783 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10677137408 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (4194304 contiguous values) -> 12828 us (1.307819 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10668748800 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (8388608 contiguous values) -> 35858 us (0.935756 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10651971584 / 12079136768
sendreceivenext (8 processes) (UVA: true) torch.CudaTensor (16777216 contiguous values) -> 70947 us (0.945897 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10618417152 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (256 contiguous values) -> 32 us (0.062655 GB/s assuming good implementation, i.e. 0.002048 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (512 contiguous values) -> 13 us (0.294680 GB/s assuming good implementation, i.e. 0.004096 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (1024 contiguous values) -> 16 us (0.509033 GB/s assuming good implementation, i.e. 0.008192 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (2048 contiguous values) -> 21 us (0.758493 GB/s assuming good implementation, i.e. 0.016384 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (4096 contiguous values) -> 32 us (0.993056 GB/s assuming good implementation, i.e. 0.032768 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (8192 contiguous values) -> 34 us (1.920880 GB/s assuming good implementation, i.e. 0.065536 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (16384 contiguous values) -> 53 us (2.473036 GB/s assuming good implementation, i.e. 0.131072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (32768 contiguous values) -> 82 us (3.193470 GB/s assuming good implementation, i.e. 0.262144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (65536 contiguous values) -> 148 us (3.521254 GB/s assuming good implementation, i.e. 0.524288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (131072 contiguous values) -> 278 us (3.767709 GB/s assuming good implementation, i.e. 1.048576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (262144 contiguous values) -> 555 us (3.775958 GB/s assuming good implementation, i.e. 2.097152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (524288 contiguous values) -> 1135 us (3.693510 GB/s assuming good implementation, i.e. 4.194304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10683428864 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (1048576 contiguous values) -> 2811 us (2.983269 GB/s assuming good implementation, i.e. 8.388608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10681331712 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (2097152 contiguous values) -> 7997 us (2.097835 GB/s assuming good implementation, i.e. 16.777216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10677137408 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (4194304 contiguous values) -> 19238 us (1.744128 GB/s assuming good implementation, i.e. 33.554432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10668748800 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (8388608 contiguous values) -> 44222 us (1.517528 GB/s assuming good implementation, i.e. 67.108864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10651971584 / 12079136768
allreduce (8 processes) (UVA: true) torch.CudaTensor (16777216 contiguous values) -> 89169 us (1.505194 GB/s assuming good implementation, i.e. 134.217728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10618433536 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (256 contiguous values) -> 17 us (0.176506 GB/s assuming good implementation, i.e. 0.003072 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (512 contiguous values) -> 8 us (0.713845 GB/s assuming good implementation, i.e. 0.006144 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (1024 contiguous values) -> 8 us (1.381759 GB/s assuming good implementation, i.e. 0.012288 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684485632 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (2048 contiguous values) -> 9 us (2.616224 GB/s assuming good implementation, i.e. 0.024576 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685583360 / 10684485632 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (4096 contiguous values) -> 11 us (4.277146 GB/s assuming good implementation, i.e. 0.049152 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685583360 / 10684502016 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (8192 contiguous values) -> 19 us (4.967673 GB/s assuming good implementation, i.e. 0.098304 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685583360 / 10684485632 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (16384 contiguous values) -> 31 us (6.280531 GB/s assuming good implementation, i.e. 0.196608 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (32768 contiguous values) -> 49 us (7.929170 GB/s assuming good implementation, i.e. 0.393216 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685583360 / 10684477440 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (65536 contiguous values) -> 125 us (6.270979 GB/s assuming good implementation, i.e. 0.786432 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684477440 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (131072 contiguous values) -> 133 us (11.765775 GB/s assuming good implementation, i.e. 1.572864 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685591552 / 10684502016 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (262144 contiguous values) -> 326 us (9.625840 GB/s assuming good implementation, i.e. 3.145728 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685566976 / 10684493824 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (524288 contiguous values) -> 482 us (13.041553 GB/s assuming good implementation, i.e. 6.291456 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685566976 / 10683453440 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (1048576 contiguous values) -> 1263 us (9.956338 GB/s assuming good implementation, i.e. 12.582912 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685558784 / 10681339904 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (2097152 contiguous values) -> 4525 us (5.561164 GB/s assuming good implementation, i.e. 25.165824 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685534208 / 10677137408 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (4194304 contiguous values) -> 8649 us (5.819286 GB/s assuming good implementation, i.e. 50.331648 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685583360 / 10668748800 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (8388608 contiguous values) -> 17145 us (5.871156 GB/s assuming good implementation, i.e. 100.663296 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685583360 / 10651971584 / 12079136768
broadcast (8 processes) (UVA: true) torch.CudaTensor (16777216 contiguous values) -> 33892 us (5.940150 GB/s assuming good implementation, i.e. 201.326592 MB through the slowest wire, assuming p2p wires) GPU memory pre / post / total alloc: 10685583360 / 10618425344 / 12079136768
